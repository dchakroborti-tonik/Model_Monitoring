{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bea500",
   "metadata": {},
   "source": [
    "# Define Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0597fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Jupyter Notebook Loading Header\n",
    "#\n",
    "# This is a custom loading header for Jupyter Notebooks in Visual Studio Code.\n",
    "# It includes common imports and settings to get you started quickly.\n",
    "# %% [markdown]\n",
    "## Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import joblib\n",
    "import uuid\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datetime import datetime, timedelta\n",
    "import gcsfs\n",
    "import duckdb as dd\n",
    "import pickle\n",
    "import joblib\n",
    "from typing import Union\n",
    "import io\n",
    "path = r'C:\\Users\\Dwaipayan\\AppData\\Roaming\\gcloud\\legacy_credentials\\dchakroborti@tonikbank.com\\adc.json'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = path\n",
    "client = bigquery.Client(project='prj-prod-dataplatform')\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"prj-prod-dataplatform\"\n",
    "\n",
    "# %% [markdown]\n",
    "## Configure Settings\n",
    "# Set options or configurations as needed\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"Display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7137df",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7140e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class GiniDashboardGenerator:\n",
    "    \"\"\"Generate Gini/AUC metrics and segmentation tables for Power BI dashboard\"\"\"\n",
    "    \n",
    "    def __init__(self, df, score_column, target_column):\n",
    "        \"\"\"\n",
    "        Initialize with configurable score and target columns\n",
    "        \n",
    "        Args:\n",
    "            df: Input dataframe\n",
    "            score_column: Name of the score column (e.g., 'Alpha_cic_sil_score')\n",
    "            target_column: Name of the target column (e.g., 'deffpd0', 'deffpd10', etc.)\n",
    "        \"\"\"\n",
    "        self.df = df.copy()\n",
    "        self.score_column = score_column\n",
    "        self.target_column = target_column\n",
    "        self.prepare_data()\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare data with disbursement month and week columns\"\"\"\n",
    "        self.df['disbursementdate'] = pd.to_datetime(self.df['disbursementdate'])\n",
    "        self.df['disbursement_month'] = self.df['disbursementdate'].dt.to_period('M')\n",
    "        self.df['disbursement_week'] = self.df['disbursementdate'].dt.to_period('W')\n",
    "        \n",
    "        # Standardize column names for internal processing\n",
    "        self.df['score'] = self.df[self.score_column]\n",
    "        self.df['Bad_Rate'] = self.df[self.target_column]\n",
    "        \n",
    "        # Add metadata to track original column names\n",
    "        self.metadata = {\n",
    "            'score_column': self.score_column,\n",
    "            'target_column': self.target_column\n",
    "        }\n",
    "        \n",
    "    def calculate_gini_auc(self, y_true, y_score):\n",
    "        \"\"\"Calculate AUC and Gini coefficient\"\"\"\n",
    "        if len(np.unique(y_true)) < 2 or len(y_true) == 0:\n",
    "            return np.nan, np.nan\n",
    "        \n",
    "        try:\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            gini = 2 * auc_score - 1\n",
    "            return auc_score, gini\n",
    "        except:\n",
    "            return np.nan, np.nan\n",
    "    \n",
    "    def generate_segments(self):\n",
    "        \"\"\"Generate all segment combinations\"\"\"\n",
    "        segments = []\n",
    "        segment_id = 1\n",
    "        \n",
    "        # Get unique values for dimensions\n",
    "        model_versions = self.df.groupby(['modelDisplayName', 'modelVersionId', 'trenchCategory']).size().reset_index()[\n",
    "            ['modelDisplayName', 'modelVersionId', 'trenchCategory']].drop_duplicates()\n",
    "        \n",
    "        new_loan_types = self.df['new_loan_type'].unique().tolist()\n",
    "        loan_product_types = self.df['loan_product_type'].unique().tolist()\n",
    "        \n",
    "        # Combination 1: Overall for each modelDisplayName+modelVersionId+trenchCategory\n",
    "        # Include ALL trench combined for each modelDisplayName+modelVersionId\n",
    "        for _, row in model_versions.iterrows():\n",
    "            model_name = row['modelDisplayName']\n",
    "            model_version = row['modelVersionId']\n",
    "            trench = row['trenchCategory']\n",
    "            \n",
    "            segments.append({\n",
    "                'segment_id': segment_id,\n",
    "                'segment_name': f\"{model_name}_{model_version}_{trench}\",\n",
    "                'modelDisplayName': model_name,\n",
    "                'modelVersionId': model_version,\n",
    "                'trenchCategory': trench,\n",
    "                'new_loan_type': 'All',\n",
    "                'loan_product_type': 'All',\n",
    "                'segment_type': 'Trench_Level'\n",
    "            })\n",
    "            segment_id += 1\n",
    "        \n",
    "        # Add \"All\" trench combining Trench 1, 2, 3\n",
    "        for model_name in self.df['modelDisplayName'].unique():\n",
    "            for model_version in self.df[self.df['modelDisplayName'] == model_name]['modelVersionId'].unique():\n",
    "                segments.append({\n",
    "                    'segment_id': segment_id,\n",
    "                    'segment_name': f\"{model_name}_{model_version}_All\",\n",
    "                    'modelDisplayName': model_name,\n",
    "                    'modelVersionId': model_version,\n",
    "                    'trenchCategory': 'All',\n",
    "                    'new_loan_type': 'All',\n",
    "                    'loan_product_type': 'All',\n",
    "                    'segment_type': 'Model_Level'\n",
    "                })\n",
    "                segment_id += 1\n",
    "        \n",
    "        # Combination 2 & 3: With new_loan_type and loan_product_type\n",
    "        for _, row in model_versions.iterrows():\n",
    "            model_name = row['modelDisplayName']\n",
    "            model_version = row['modelVersionId']\n",
    "            trench = row['trenchCategory']\n",
    "            \n",
    "            # Combination 3: Each combination of new_loan_type and loan_product_type\n",
    "            for loan_type in new_loan_types:\n",
    "                segments.append({\n",
    "                    'segment_id': segment_id,\n",
    "                    'segment_name': f\"{model_name}_{model_version}_{trench}_{loan_type}\",\n",
    "                    'modelDisplayName': model_name,\n",
    "                    'modelVersionId': model_version,\n",
    "                    'trenchCategory': trench,\n",
    "                    'new_loan_type': loan_type,\n",
    "                    'loan_product_type': 'All',\n",
    "                    'segment_type': 'Loan_Type_Level'\n",
    "                })\n",
    "                segment_id += 1\n",
    "            \n",
    "            for product_type in loan_product_types:\n",
    "                segments.append({\n",
    "                    'segment_id': segment_id,\n",
    "                    'segment_name': f\"{model_name}_{model_version}_{trench}_{product_type}\",\n",
    "                    'modelDisplayName': model_name,\n",
    "                    'modelVersionId': model_version,\n",
    "                    'trenchCategory': trench,\n",
    "                    'new_loan_type': 'All',\n",
    "                    'loan_product_type': product_type,\n",
    "                    'segment_type': 'Product_Type_Level'\n",
    "                })\n",
    "                segment_id += 1\n",
    "            \n",
    "            # Both new_loan_type and loan_product_type\n",
    "            for loan_type in new_loan_types:\n",
    "                for product_type in loan_product_types:\n",
    "                    segments.append({\n",
    "                        'segment_id': segment_id,\n",
    "                        'segment_name': f\"{model_name}_{model_version}_{trench}_{loan_type}_{product_type}\",\n",
    "                        'modelDisplayName': model_name,\n",
    "                        'modelVersionId': model_version,\n",
    "                        'trenchCategory': trench,\n",
    "                        'new_loan_type': loan_type,\n",
    "                        'loan_product_type': product_type,\n",
    "                        'segment_type': 'Full_Level'\n",
    "                    })\n",
    "                    segment_id += 1\n",
    "        \n",
    "        self.dim_segment = pd.DataFrame(segments)\n",
    "        return self.dim_segment\n",
    "    \n",
    "    def filter_data(self, model_name, model_version, trench, loan_type, product_type):\n",
    "        \"\"\"Filter dataframe based on segment criteria\"\"\"\n",
    "        df_filtered = self.df[\n",
    "            (self.df['modelDisplayName'] == model_name) &\n",
    "            (self.df['modelVersionId'] == model_version)\n",
    "        ]\n",
    "        \n",
    "        if trench != 'All':\n",
    "            df_filtered = df_filtered[df_filtered['trenchCategory'] == trench]\n",
    "        else:\n",
    "            # Combine all trenches\n",
    "            trenches = ['Trench 1', 'Trench 2', 'Trench 3']\n",
    "            df_filtered = df_filtered[df_filtered['trenchCategory'].isin(trenches)]\n",
    "        \n",
    "        if loan_type != 'All':\n",
    "            df_filtered = df_filtered[df_filtered['new_loan_type'] == loan_type]\n",
    "        \n",
    "        if product_type != 'All':\n",
    "            df_filtered = df_filtered[df_filtered['loan_product_type'] == product_type]\n",
    "        \n",
    "        return df_filtered\n",
    "    \n",
    "    def calculate_score_deciles_and_cumulative(self, df_data, segment_id, time_period, time_type):\n",
    "        \"\"\"Calculate decile-based metrics and cumulative statistics for DAX calculations\"\"\"\n",
    "        if len(df_data) == 0:\n",
    "            return []\n",
    "        \n",
    "        decile_records = []\n",
    "        decile_id = 1\n",
    "        \n",
    "        # Sort by score descending to create deciles (rank 1 = highest score)\n",
    "        df_sorted = df_data.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        # Create deciles\n",
    "        df_sorted['decile'] = pd.qcut(df_sorted['score'].rank(method='first'), \n",
    "                                       q=10, labels=False, duplicates='drop') + 1\n",
    "        df_sorted['decile'] = 10 - df_sorted['decile'] + 1  # Reverse so 1 = lowest score, 10 = highest\n",
    "        \n",
    "        total_records = len(df_sorted)\n",
    "        total_bads = df_sorted['Bad_Rate'].sum()\n",
    "        total_goods = total_records - total_bads\n",
    "        \n",
    "        cum_records = 0\n",
    "        cum_bads = 0\n",
    "        cum_goods = 0\n",
    "        \n",
    "        # Calculate metrics per decile\n",
    "        for decile in sorted(df_sorted['decile'].unique()):\n",
    "            df_decile = df_sorted[df_sorted['decile'] == decile]\n",
    "            decile_records_count = len(df_decile)\n",
    "            decile_bads = df_decile['Bad_Rate'].sum()\n",
    "            decile_goods = decile_records_count - decile_bads\n",
    "            \n",
    "            cum_records += decile_records_count\n",
    "            cum_bads += decile_bads\n",
    "            cum_goods += decile_goods\n",
    "            \n",
    "            decile_records.append({\n",
    "                'segment_id': segment_id,\n",
    "                'time_period': time_period,\n",
    "                'time_type': time_type,\n",
    "                'decile': decile,\n",
    "                'score_min': df_decile['score'].min(),\n",
    "                'score_max': df_decile['score'].max(),\n",
    "                'score_avg': df_decile['score'].mean(),\n",
    "                'records_in_decile': decile_records_count,\n",
    "                'bads_in_decile': int(decile_bads),\n",
    "                'goods_in_decile': decile_goods,\n",
    "                'pct_records': (decile_records_count / total_records * 100) if total_records > 0 else 0,\n",
    "                'pct_bads': (decile_bads / total_bads * 100) if total_bads > 0 else 0,\n",
    "                'pct_goods': (decile_goods / total_goods * 100) if total_goods > 0 else 0,\n",
    "                'cum_records': cum_records,\n",
    "                'cum_bads': int(cum_bads),\n",
    "                'cum_goods': cum_goods,\n",
    "                'cum_pct_records': (cum_records / total_records * 100) if total_records > 0 else 0,\n",
    "                'cum_pct_bads': (cum_bads / total_bads * 100) if total_bads > 0 else 0,\n",
    "                'cum_pct_goods': (cum_goods / total_goods * 100) if total_goods > 0 else 0,\n",
    "                'bad_rate_decile': (decile_bads / decile_records_count * 100) if decile_records_count > 0 else 0,\n",
    "                'total_records': total_records,\n",
    "                'total_bads': total_bads,\n",
    "                'total_goods': total_goods\n",
    "            })\n",
    "            decile_id += 1\n",
    "        \n",
    "        return decile_records\n",
    "    \n",
    "    def calculate_metrics(self):\n",
    "        \"\"\"Calculate AUC and Gini for all segments and time periods\"\"\"\n",
    "        facts = []\n",
    "        deciles = []\n",
    "        fact_id = 1\n",
    "        \n",
    "        for idx, segment in self.dim_segment.iterrows():\n",
    "            df_segment = self.filter_data(\n",
    "                segment['modelDisplayName'],\n",
    "                segment['modelVersionId'],\n",
    "                segment['trenchCategory'],\n",
    "                segment['new_loan_type'],\n",
    "                segment['loan_product_type']\n",
    "            )\n",
    "            \n",
    "            # Overall metrics\n",
    "            if len(df_segment) > 0:\n",
    "                auc_score, gini = self.calculate_gini_auc(\n",
    "                    df_segment['Bad_Rate'].values,\n",
    "                    df_segment['score'].values\n",
    "                )\n",
    "                \n",
    "                facts.append({\n",
    "                    'fact_id': fact_id,\n",
    "                    'segment_id': segment['segment_id'],\n",
    "                    'segment_rank': idx + 1,\n",
    "                    'time_period': 'Overall',\n",
    "                    'time_type': 'Overall',\n",
    "                    'disbursement_month': 'All',\n",
    "                    'disbursement_week': 'All',\n",
    "                    'auc': auc_score,\n",
    "                    'gini': gini,\n",
    "                    'record_count': len(df_segment),\n",
    "                    'bad_count': int(df_segment['Bad_Rate'].sum()),\n",
    "                    'good_count': len(df_segment) - int(df_segment['Bad_Rate'].sum()),\n",
    "                    'bad_rate_pct': (df_segment['Bad_Rate'].sum() / len(df_segment) * 100) if len(df_segment) > 0 else 0\n",
    "                })\n",
    "                fact_id += 1\n",
    "                \n",
    "                # Generate decile data for this segment\n",
    "                decile_data = self.calculate_score_deciles_and_cumulative(\n",
    "                    df_segment, segment['segment_id'], 'Overall', 'Overall'\n",
    "                )\n",
    "                deciles.extend(decile_data)\n",
    "            \n",
    "            # Monthly metrics\n",
    "            for month in df_segment['disbursement_month'].unique():\n",
    "                df_month = df_segment[df_segment['disbursement_month'] == month]\n",
    "                \n",
    "                if len(df_month) > 0:\n",
    "                    auc_score, gini = self.calculate_gini_auc(\n",
    "                        df_month['Bad_Rate'].values,\n",
    "                        df_month['score'].values\n",
    "                    )\n",
    "                    \n",
    "                    facts.append({\n",
    "                        'fact_id': fact_id,\n",
    "                        'segment_id': segment['segment_id'],\n",
    "                        'segment_rank': idx + 1,\n",
    "                        'time_period': str(month),\n",
    "                        'time_type': 'Month',\n",
    "                        'disbursement_month': str(month),\n",
    "                        'disbursement_week': 'All',\n",
    "                        'auc': auc_score,\n",
    "                        'gini': gini,\n",
    "                        'record_count': len(df_month),\n",
    "                        'bad_count': int(df_month['Bad_Rate'].sum()),\n",
    "                        'good_count': len(df_month) - int(df_month['Bad_Rate'].sum()),\n",
    "                        'bad_rate_pct': (df_month['Bad_Rate'].sum() / len(df_month) * 100) if len(df_month) > 0 else 0\n",
    "                    })\n",
    "                    fact_id += 1\n",
    "                    \n",
    "                    # Generate decile data for this month\n",
    "                    decile_data = self.calculate_score_deciles_and_cumulative(\n",
    "                        df_month, segment['segment_id'], str(month), 'Month'\n",
    "                    )\n",
    "                    deciles.extend(decile_data)\n",
    "            \n",
    "            # Weekly metrics\n",
    "            for week in df_segment['disbursement_week'].unique():\n",
    "                df_week = df_segment[df_segment['disbursement_week'] == week]\n",
    "                \n",
    "                if len(df_week) > 0:\n",
    "                    auc_score, gini = self.calculate_gini_auc(\n",
    "                        df_week['Bad_Rate'].values,\n",
    "                        df_week['score'].values\n",
    "                    )\n",
    "                    \n",
    "                    facts.append({\n",
    "                        'fact_id': fact_id,\n",
    "                        'segment_id': segment['segment_id'],\n",
    "                        'segment_rank': idx + 1,\n",
    "                        'time_period': str(week),\n",
    "                        'time_type': 'Week',\n",
    "                        'disbursement_month': 'All',\n",
    "                        'disbursement_week': str(week),\n",
    "                        'auc': auc_score,\n",
    "                        'gini': gini,\n",
    "                        'record_count': len(df_week),\n",
    "                        'bad_count': int(df_week['Bad_Rate'].sum()),\n",
    "                        'good_count': len(df_week) - int(df_week['Bad_Rate'].sum()),\n",
    "                        'bad_rate_pct': (df_week['Bad_Rate'].sum() / len(df_week) * 100) if len(df_week) > 0 else 0\n",
    "                    })\n",
    "                    fact_id += 1\n",
    "                    \n",
    "                    # Generate decile data for this week\n",
    "                    decile_data = self.calculate_score_deciles_and_cumulative(\n",
    "                        df_week, segment['segment_id'], str(week), 'Week'\n",
    "                    )\n",
    "                    deciles.extend(decile_data)\n",
    "        \n",
    "        self.fact_metrics = pd.DataFrame(facts)\n",
    "        self.fact_deciles = pd.DataFrame(deciles)\n",
    "        return self.fact_metrics\n",
    "    \n",
    "    def generate_all(self):\n",
    "        \"\"\"Generate all tables\"\"\"\n",
    "        self.generate_segments()\n",
    "        self.calculate_metrics()\n",
    "        \n",
    "        return {\n",
    "            'fact_metrics': self.fact_metrics,\n",
    "            'fact_deciles': self.fact_deciles,\n",
    "            'dim_segment': self.dim_segment,\n",
    "            'metadata': self.metadata\n",
    "        }\n",
    "    \n",
    "    def save_tables(self, output_path='./', target_suffix=''):\n",
    "        \"\"\"\n",
    "        Save fact and dimension tables to CSV\n",
    "        \n",
    "        Args:\n",
    "            output_path: Path to save files\n",
    "            target_suffix: Suffix to append to filenames (e.g., '_deffpd0', '_deffpd10')\n",
    "        \"\"\"\n",
    "        suffix = f'_{target_suffix}' if target_suffix else ''\n",
    "        \n",
    "        self.fact_metrics.to_csv(f'{output_path}fact_metrics{suffix}.csv', index=False)\n",
    "        self.fact_deciles.to_csv(f'{output_path}fact_deciles{suffix}.csv', index=False)\n",
    "        self.dim_segment.to_csv(f'{output_path}dim_segment{suffix}.csv', index=False)\n",
    "        \n",
    "        print(f\"✓ Fact metrics table saved: {output_path}fact_metrics{suffix}.csv ({len(self.fact_metrics)} rows)\")\n",
    "        print(f\"✓ Fact deciles table saved: {output_path}fact_deciles{suffix}.csv ({len(self.fact_deciles)} rows)\")\n",
    "        print(f\"✓ Dimension segment table saved: {output_path}dim_segment{suffix}.csv ({len(self.dim_segment)} rows)\")\n",
    "        print(f\"  Score Column: {self.metadata['score_column']}, Target Column: {self.metadata['target_column']}\")\n",
    "\n",
    "\n",
    "# # Usage Example with Multiple Targets\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     # Define all target columns and their corresponding score columns\n",
    "#     targets = [\n",
    "#         {'target': 'deffpd0', 'score': 'Alpha_cic_sil_score', 'suffix': 'deffpd0'},\n",
    "#         {'target': 'deffpd10', 'score': 'Alpha_cic_sil_score', 'suffix': 'deffpd10'},\n",
    "#         {'target': 'deffpd30', 'score': 'Alpha_cic_sil_score', 'suffix': 'deffpd30'},\n",
    "#     ]\n",
    "    \n",
    "#     all_fact_metrics = []\n",
    "#     all_fact_deciles = []\n",
    "#     all_dim_segments = []\n",
    "    \n",
    "#     # Process each target\n",
    "#     for config in targets:\n",
    "#         print(f\"\\n{'='*60}\")\n",
    "#         print(f\"Processing: {config['suffix']}\")\n",
    "#         print(f\"{'='*60}\")\n",
    "        \n",
    "#         # Initialize generator with specific score and target columns\n",
    "#         generator = GiniDashboardGenerator(\n",
    "#             df_concat,\n",
    "#             score_column=config['score'],\n",
    "#             target_column=config['target']\n",
    "#         )\n",
    "        \n",
    "#         # Generate all tables\n",
    "#         tables = generator.generate_all()\n",
    "        \n",
    "#         # Save individual tables with suffix\n",
    "#         generator.save_tables(output_path='./', target_suffix=config['suffix'])\n",
    "        \n",
    "#         # Add target column info for concatenation\n",
    "#         tables['fact_metrics']['target_column'] = config['target']\n",
    "#         tables['fact_deciles']['target_column'] = config['target']\n",
    "#         tables['dim_segment']['target_column'] = config['target']\n",
    "        \n",
    "#         # Collect for concatenation\n",
    "#         all_fact_metrics.append(tables['fact_metrics'])\n",
    "#         all_fact_deciles.append(tables['fact_deciles'])\n",
    "#         all_dim_segments.append(tables['dim_segment'])\n",
    "        \n",
    "#         # Display sample\n",
    "#         print(f\"\\nSample metrics (first 5 rows):\")\n",
    "#         print(tables['fact_metrics'][['segment_rank', 'time_type', 'gini', 'record_count']].head())\n",
    "    \n",
    "#     # Concatenate all results\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(\"CONCATENATING ALL TARGETS\")\n",
    "#     print(f\"{'='*60}\")\n",
    "    \n",
    "#     combined_fact_metrics = pd.concat(all_fact_metrics, ignore_index=True)\n",
    "#     combined_fact_deciles = pd.concat(all_fact_deciles, ignore_index=True)\n",
    "#     combined_dim_segment = pd.concat(all_dim_segments, ignore_index=True).drop_duplicates()\n",
    "    \n",
    "#     # Save combined tables\n",
    "#     combined_fact_metrics.to_csv('./fact_metrics_combined.csv', index=False)\n",
    "#     combined_fact_deciles.to_csv('./fact_deciles_combined.csv', index=False)\n",
    "#     combined_dim_segment.to_csv('./dim_segment_combined.csv', index=False)\n",
    "    \n",
    "#     print(f\"✓ Combined fact metrics: ./fact_metrics_combined.csv ({len(combined_fact_metrics)} rows)\")\n",
    "#     print(f\"✓ Combined fact deciles: ./fact_deciles_combined.csv ({len(combined_fact_deciles)} rows)\")\n",
    "#     print(f\"✓ Combined dimension segment: ./dim_segment_combined.csv ({len(combined_dim_segment)} rows)\")\n",
    "    \n",
    "#     # Display combined sample\n",
    "#     print(f\"\\n=== COMBINED FACT METRICS SAMPLE ===\")\n",
    "#     print(combined_fact_metrics[['target_column', 'segment_rank', 'time_type', 'gini', 'record_count']].head(10))\n",
    "    \n",
    "#     print(f\"\\n=== DIMENSION SEGMENT (Combined, Unique) ===\")\n",
    "#     print(combined_dim_segment[['segment_id', 'segment_name', 'target_column']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8c983",
   "metadata": {},
   "source": [
    "## calculate_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef8b5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini(pd_scores, bad_indicators):\n",
    "    \"\"\"\n",
    "    Calculate Gini coefficient from scores and binary indicators\n",
    "    \n",
    "    Parameters:\n",
    "    pd_scores: array-like of scores/probabilities\n",
    "    bad_indicators: array-like of binary outcomes (0/1)\n",
    "    \n",
    "    Returns:\n",
    "    float: Gini coefficient\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays and ensure they're numeric\n",
    "    pd_scores = np.array(pd_scores, dtype=float)\n",
    "    bad_indicators = np.array(bad_indicators, dtype=int)\n",
    "    \n",
    "    # Check for valid input data\n",
    "    if len(pd_scores) == 0 or len(bad_indicators) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Check if we have both good and bad cases (needed for ROC AUC)\n",
    "    if len(np.unique(bad_indicators)) < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate AUC using sklearn\n",
    "    try:\n",
    "        auc = roc_auc_score(bad_indicators, pd_scores)\n",
    "        # Calculate Gini from AUC\n",
    "        gini = 2 * auc - 1\n",
    "        return gini\n",
    "    except ValueError:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed167ded",
   "metadata": {},
   "source": [
    "## calculate_periodic_gini_prod_ver_trench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe2750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_periodic_gini_prod_ver_trench(df, score_column, label_column, namecolumn, \n",
    "                                        model_version_column=None, trench_column=None, \n",
    "                                        loan_type_column=None, loan_product_type_column=None):\n",
    "    \"\"\"\n",
    "    Calculate periodic Gini coefficients at multiple levels:\n",
    "    - Overall\n",
    "    - By model version\n",
    "    - By all combinations of model version, trench category, loan type, and loan product type\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with disbursement dates and score/label columns\n",
    "    score_column: name of the score column\n",
    "    label_column: name of the label column\n",
    "    namecolumn: name for the bad rate label\n",
    "    model_version_column: (optional) name of column for model version (e.g., 'modelVersionId')\n",
    "    trench_column: (optional) name of column for trench category (e.g., 'trenchCategory')\n",
    "    loan_type_column: (optional) name of loan type column (e.g., 'loan_type')\n",
    "    loan_product_type_column: (optional) name of loan product type column (e.g., 'loan_product_type')\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    required_columns = ['disbursementdate', score_column, label_column]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns. Need: {required_columns}\")\n",
    "    \n",
    "    optional_columns = {\n",
    "        'model_version': model_version_column,\n",
    "        'trench': trench_column,\n",
    "        'loan_type': loan_type_column,\n",
    "        'loan_product_type': loan_product_type_column\n",
    "    }\n",
    "    \n",
    "    for col_name, col in optional_columns.items():\n",
    "        if col and col not in df.columns:\n",
    "            raise ValueError(f\"{col_name.replace('_', ' ').title()} column '{col}' not found in dataframe\")\n",
    "    \n",
    "    # Create a copy to avoid modifying original dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date is datetime type\n",
    "    df['disbursementdate'] = pd.to_datetime(df['disbursementdate'])\n",
    "    \n",
    "    # Ensure score and label columns are numeric\n",
    "    df[score_column] = pd.to_numeric(df[score_column], errors='coerce')\n",
    "    df[label_column] = pd.to_numeric(df[label_column], errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid values\n",
    "    df = df.dropna(subset=[score_column, label_column])\n",
    "    \n",
    "    # Define list of datasets to process\n",
    "    datasets_to_process = [('Overall', df, {})]\n",
    "    \n",
    "    # Add model version level segmentation\n",
    "    if model_version_column:\n",
    "        for model_version in sorted(df[model_version_column].dropna().unique()):\n",
    "            model_df = df[df[model_version_column] == model_version]\n",
    "            metadata = {model_version_column: model_version}\n",
    "            datasets_to_process.append((f'ModelVersion_{model_version}', model_df, metadata))\n",
    "    \n",
    "    # Add all combinations of model_version, trench, loan_type, loan_product_type\n",
    "    segment_columns = []\n",
    "    if model_version_column:\n",
    "        segment_columns.append(('ModelVersion', model_version_column))\n",
    "    if trench_column:\n",
    "        segment_columns.append(('Trench', trench_column))\n",
    "    if loan_type_column:\n",
    "        segment_columns.append(('LoanType', loan_type_column))\n",
    "    if loan_product_type_column:\n",
    "        segment_columns.append(('ProductType', loan_product_type_column))\n",
    "    \n",
    "    # Generate all combinations (only if we have multiple segment columns)\n",
    "    if len(segment_columns) > 1:\n",
    "        # Create combinations by iterating through all segment dimensions\n",
    "        def generate_combinations(df, segment_columns, index=0, current_filter=None, current_name=''):\n",
    "            if current_filter is None:\n",
    "                current_filter = {}\n",
    "            \n",
    "            if index >= len(segment_columns):\n",
    "                # Apply all filters and create segment\n",
    "                filtered_df = df\n",
    "                for col, val in current_filter.items():\n",
    "                    filtered_df = filtered_df[filtered_df[col] == val]\n",
    "                \n",
    "                if len(filtered_df) > 0:\n",
    "                    yield (current_name.strip('_'), filtered_df, current_filter.copy())\n",
    "                return\n",
    "            \n",
    "            seg_name, seg_col = segment_columns[index]\n",
    "            for seg_value in sorted(df[seg_col].dropna().unique()):\n",
    "                new_filter = current_filter.copy()\n",
    "                new_filter[seg_col] = seg_value\n",
    "                new_name = current_name + f'{seg_name}_{seg_value}_'\n",
    "                \n",
    "                yield from generate_combinations(df, segment_columns, index + 1, new_filter, new_name)\n",
    "        \n",
    "        for combo_name, combo_df, combo_metadata in generate_combinations(df, segment_columns):\n",
    "            datasets_to_process.append((combo_name, combo_df, combo_metadata))\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Process each dataset\n",
    "    for dataset_name, dataset_df, metadata in datasets_to_process:\n",
    "        # Calculate weekly Gini\n",
    "        dataset_df_copy = dataset_df.copy()\n",
    "        dataset_df_copy['week'] = dataset_df_copy['disbursementdate'].dt.to_period('W')\n",
    "        weekly_gini = dataset_df_copy.groupby('week').apply(\n",
    "            lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "            if len(x) >= 10 else np.nan\n",
    "        ).reset_index(name='gini')\n",
    "        weekly_gini['period'] = 'Week'\n",
    "        weekly_gini['start_date'] = weekly_gini['week'].apply(lambda x: x.to_timestamp())\n",
    "        weekly_gini['end_date'] = weekly_gini['start_date'] + timedelta(days=6)\n",
    "        weekly_gini = weekly_gini[['start_date', 'end_date', 'gini', 'period']]\n",
    "        \n",
    "        # Calculate monthly Gini\n",
    "        dataset_df_copy = dataset_df.copy()\n",
    "        dataset_df_copy['month'] = dataset_df_copy['disbursementdate'].dt.to_period('M')\n",
    "        monthly_gini = dataset_df_copy.groupby('month').apply(\n",
    "            lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "            if len(x) >= 20 else np.nan\n",
    "        ).reset_index(name='gini')\n",
    "        monthly_gini['period'] = 'Month'\n",
    "        monthly_gini['start_date'] = monthly_gini['month'].apply(lambda x: x.to_timestamp())\n",
    "        monthly_gini['end_date'] = monthly_gini['start_date'] + pd.DateOffset(months=1) - pd.Timedelta(days=1)\n",
    "        monthly_gini = monthly_gini[['start_date', 'end_date', 'gini', 'period']]\n",
    "        \n",
    "        # Combine results for this dataset\n",
    "        gini_results = pd.concat([weekly_gini, monthly_gini], ignore_index=True)\n",
    "        gini_results = gini_results.sort_values(by='start_date').reset_index(drop=True)\n",
    "        \n",
    "        # Add metadata columns\n",
    "        gini_results['Model_Name'] = score_column\n",
    "        gini_results['bad_rate'] = namecolumn\n",
    "        gini_results['segment_type'] = dataset_name\n",
    "        \n",
    "        # Add individual segment components\n",
    "        if model_version_column and model_version_column in metadata:\n",
    "            gini_results['model_version'] = metadata[model_version_column]\n",
    "        else:\n",
    "            gini_results['model_version'] = None\n",
    "        \n",
    "        if trench_column and trench_column in metadata:\n",
    "            gini_results['trench_category'] = metadata[trench_column]\n",
    "        else:\n",
    "            gini_results['trench_category'] = None\n",
    "        \n",
    "        if loan_type_column and loan_type_column in metadata:\n",
    "            gini_results['loan_type'] = metadata[loan_type_column]\n",
    "        else:\n",
    "            gini_results['loan_type'] = None\n",
    "        \n",
    "        if loan_product_type_column and loan_product_type_column in metadata:\n",
    "            gini_results['loan_product_type'] = metadata[loan_product_type_column]\n",
    "        else:\n",
    "            gini_results['loan_product_type'] = None\n",
    "        \n",
    "        gini_results.rename(columns={'gini': f'{score_column}_{namecolumn}_gini'}, inplace=True)\n",
    "        \n",
    "        all_results.append(gini_results)\n",
    "    \n",
    "    # Combine all results\n",
    "    final_results = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# gini_results = calculate_periodic_gini_prod_ver_trench(\n",
    "#     df_concat, \n",
    "#     'Alpha_cic_sil_score', \n",
    "#     'deffpd0', \n",
    "#     'FPD0',\n",
    "#     model_version_column='modelVersionId',\n",
    "#     trench_column='trenchCategory',\n",
    "#     loan_type_column='loan_type',\n",
    "#     loan_product_type_column='loan_product_type'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a006dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_periodic_gini_prod_ver_trench_md(df, score_column, label_column, namecolumn, \n",
    "#                                         model_version_column=None, trench_column=None, \n",
    "#                                         loan_type_column=None, loan_product_type_column=None,\n",
    "#                                         account_id_column=None):\n",
    "#     \"\"\"\n",
    "#     Calculate periodic Gini coefficients at multiple levels:\n",
    "#     - Overall\n",
    "#     - By model version\n",
    "#     - By all combinations of model version, trench category, loan type, and loan product type\n",
    "    \n",
    "#     Parameters:\n",
    "#     df: DataFrame with disbursement dates and score/label columns\n",
    "#     score_column: name of the score column\n",
    "#     label_column: name of the label column\n",
    "#     namecolumn: name for the bad rate label\n",
    "#     model_version_column: (optional) name of column for model version (e.g., 'modelVersionId')\n",
    "#     trench_column: (optional) name of column for trench category (e.g., 'trenchCategory')\n",
    "#     loan_type_column: (optional) name of loan type column (e.g., 'loan_type')\n",
    "#     loan_product_type_column: (optional) name of loan product type column (e.g., 'loan_product_type')\n",
    "#     account_id_column: (optional) name of column for distinct account IDs (e.g., 'digitalLoanAccountId')\n",
    "#     \"\"\"\n",
    "#     # Input validation\n",
    "#     required_columns = ['disbursementdate', score_column, label_column]\n",
    "#     if not all(col in df.columns for col in required_columns):\n",
    "#         raise ValueError(f\"Missing required columns. Need: {required_columns}\")\n",
    "    \n",
    "#     optional_columns = {\n",
    "#         'model_version': model_version_column,\n",
    "#         'trench': trench_column,\n",
    "#         'loan_type': loan_type_column,\n",
    "#         'loan_product_type': loan_product_type_column,\n",
    "#         'account_id': account_id_column\n",
    "#     }\n",
    "    \n",
    "#     for col_name, col in optional_columns.items():\n",
    "#         if col and col not in df.columns:\n",
    "#             raise ValueError(f\"{col_name.replace('_', ' ').title()} column '{col}' not found in dataframe\")\n",
    "    \n",
    "#     # Create a copy to avoid modifying original dataframe\n",
    "#     df = df.copy()\n",
    "    \n",
    "#     # Ensure date is datetime type\n",
    "#     df['disbursementdate'] = pd.to_datetime(df['disbursementdate'])\n",
    "    \n",
    "#     # Ensure score and label columns are numeric\n",
    "#     df[score_column] = pd.to_numeric(df[score_column], errors='coerce')\n",
    "#     df[label_column] = pd.to_numeric(df[label_column], errors='coerce')\n",
    "    \n",
    "#     # Drop rows with invalid values\n",
    "#     df = df.dropna(subset=[score_column, label_column])\n",
    "    \n",
    "#     # Define list of datasets to process\n",
    "#     datasets_to_process = [('Overall', df, {})]\n",
    "    \n",
    "#     # Add model version level segmentation\n",
    "#     if model_version_column:\n",
    "#         for model_version in sorted(df[model_version_column].dropna().unique()):\n",
    "#             model_df = df[df[model_version_column] == model_version]\n",
    "#             metadata = {model_version_column: model_version}\n",
    "#             datasets_to_process.append((f'ModelVersion_{model_version}', model_df, metadata))\n",
    "    \n",
    "#     # Add all combinations of model_version, trench, loan_type, loan_product_type\n",
    "#     segment_columns = []\n",
    "#     if model_version_column:\n",
    "#         segment_columns.append(('ModelVersion', model_version_column))\n",
    "#     if trench_column:\n",
    "#         segment_columns.append(('Trench', trench_column))\n",
    "#     if loan_type_column:\n",
    "#         segment_columns.append(('LoanType', loan_type_column))\n",
    "#     if loan_product_type_column:\n",
    "#         segment_columns.append(('ProductType', loan_product_type_column))\n",
    "    \n",
    "#     # Generate all combinations (only if we have multiple segment columns)\n",
    "#     if len(segment_columns) > 1:\n",
    "#         # Create combinations by iterating through all segment dimensions\n",
    "#         def generate_combinations(df, segment_columns, index=0, current_filter=None, current_name=''):\n",
    "#             if current_filter is None:\n",
    "#                 current_filter = {}\n",
    "            \n",
    "#             if index >= len(segment_columns):\n",
    "#                 # Apply all filters and create segment\n",
    "#                 filtered_df = df\n",
    "#                 for col, val in current_filter.items():\n",
    "#                     filtered_df = filtered_df[filtered_df[col] == val]\n",
    "                \n",
    "#                 if len(filtered_df) > 0:\n",
    "#                     yield (current_name.strip('_'), filtered_df, current_filter.copy())\n",
    "#                 return\n",
    "            \n",
    "#             seg_name, seg_col = segment_columns[index]\n",
    "#             for seg_value in sorted(df[seg_col].dropna().unique()):\n",
    "#                 new_filter = current_filter.copy()\n",
    "#                 new_filter[seg_col] = seg_value\n",
    "#                 new_name = current_name + f'{seg_name}_{seg_value}_'\n",
    "                \n",
    "#                 yield from generate_combinations(df, segment_columns, index + 1, new_filter, new_name)\n",
    "        \n",
    "#         for combo_name, combo_df, combo_metadata in generate_combinations(df, segment_columns):\n",
    "#             datasets_to_process.append((combo_name, combo_df, combo_metadata))\n",
    "    \n",
    "#     all_results = []\n",
    "    \n",
    "#     # Process each dataset\n",
    "#     for dataset_name, dataset_df, metadata in datasets_to_process:\n",
    "#         # Calculate weekly Gini\n",
    "#         dataset_df_copy = dataset_df.copy()\n",
    "#         dataset_df_copy['week'] = dataset_df_copy['disbursementdate'].dt.to_period('W')\n",
    "#         weekly_gini = dataset_df_copy.groupby('week').apply(\n",
    "#             lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "#             if len(x) >= 10 else np.nan\n",
    "#         ).reset_index(name='gini')\n",
    "#         weekly_gini['period'] = 'Week'\n",
    "#         weekly_gini['start_date'] = weekly_gini['week'].apply(lambda x: x.to_timestamp())\n",
    "#         weekly_gini['end_date'] = weekly_gini['start_date'] + timedelta(days=6)\n",
    "        \n",
    "#         # Add distinct account count for weekly\n",
    "#         if account_id_column:\n",
    "#             weekly_gini['distinct_accounts'] = dataset_df_copy.groupby('week')[account_id_column].nunique().values\n",
    "        \n",
    "#         weekly_gini = weekly_gini[['start_date', 'end_date', 'gini', 'period']]\n",
    "        \n",
    "#         # Calculate monthly Gini\n",
    "#         dataset_df_copy = dataset_df.copy()\n",
    "#         dataset_df_copy['month'] = dataset_df_copy['disbursementdate'].dt.to_period('M')\n",
    "#         monthly_gini = dataset_df_copy.groupby('month').apply(\n",
    "#             lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "#             if len(x) >= 20 else np.nan\n",
    "#         ).reset_index(name='gini')\n",
    "#         monthly_gini['period'] = 'Month'\n",
    "#         monthly_gini['start_date'] = monthly_gini['month'].apply(lambda x: x.to_timestamp())\n",
    "#         monthly_gini['end_date'] = monthly_gini['start_date'] + pd.DateOffset(months=1) - pd.Timedelta(days=1)\n",
    "        \n",
    "#         # Add distinct account count for monthly\n",
    "#         if account_id_column:\n",
    "#             monthly_gini['distinct_accounts'] = dataset_df_copy.groupby('month')[account_id_column].nunique().values\n",
    "        \n",
    "#         monthly_gini = monthly_gini[['start_date', 'end_date', 'gini', 'period']]\n",
    "        \n",
    "#         # Combine results for this dataset\n",
    "#         gini_results = pd.concat([weekly_gini, monthly_gini], ignore_index=True)\n",
    "#         gini_results = gini_results.sort_values(by='start_date').reset_index(drop=True)\n",
    "        \n",
    "#         # Add metadata columns\n",
    "#         gini_results['Model_Name'] = score_column\n",
    "#         gini_results['bad_rate'] = namecolumn\n",
    "#         gini_results['segment_type'] = dataset_name\n",
    "        \n",
    "#         # Add individual segment components\n",
    "#         if model_version_column and model_version_column in metadata:\n",
    "#             gini_results['model_version'] = metadata[model_version_column]\n",
    "#         else:\n",
    "#             gini_results['model_version'] = None\n",
    "        \n",
    "#         if trench_column and trench_column in metadata:\n",
    "#             gini_results['trench_category'] = metadata[trench_column]\n",
    "#         else:\n",
    "#             gini_results['trench_category'] = None\n",
    "        \n",
    "#         if loan_type_column and loan_type_column in metadata:\n",
    "#             gini_results['loan_type'] = metadata[loan_type_column]\n",
    "#         else:\n",
    "#             gini_results['loan_type'] = None\n",
    "        \n",
    "#         if loan_product_type_column and loan_product_type_column in metadata:\n",
    "#             gini_results['loan_product_type'] = metadata[loan_product_type_column]\n",
    "#         else:\n",
    "#             gini_results['loan_product_type'] = None\n",
    "        \n",
    "#         gini_results.rename(columns={'gini': f'{score_column}_{namecolumn}_gini'}, inplace=True)\n",
    "        \n",
    "#         all_results.append(gini_results)\n",
    "    \n",
    "#     # Combine all results\n",
    "#     final_results = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "#     return final_results\n",
    "\n",
    "\n",
    "# # Usage:\n",
    "# # gini_results = calculate_periodic_gini_prod_ver_trench(\n",
    "# #     df_concat, \n",
    "# #     'Alpha_cic_sil_score', \n",
    "# #     'deffpd0', \n",
    "# #     'FPD0',\n",
    "# #     model_version_column='modelVersionId',\n",
    "# #     trench_column='trenchCategory',\n",
    "# #     loan_type_column='loan_type',\n",
    "# #     loan_product_type_column='loan_product_type',\n",
    "# #     account_id_column='digitalLoanAccountId'\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad30d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from itertools import combinations\n",
    "\n",
    "def calculate_gini(scores, labels):\n",
    "    \"\"\"Calculate Gini coefficient\"\"\"\n",
    "    n = len(scores)\n",
    "    if n < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    sorted_indices = np.argsort(scores)\n",
    "    sorted_labels = labels.iloc[sorted_indices].values\n",
    "    cumsum_labels = np.cumsum(sorted_labels)\n",
    "    \n",
    "    gini = 1 - 2 * np.sum(cumsum_labels) / (n * np.sum(sorted_labels))\n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_periodic_gini_prod_ver_trench_md(df, score_column, label_column, namecolumn, \n",
    "                                        model_version_column=None, trench_column=None, \n",
    "                                        loan_type_column=None, loan_product_type_column=None,\n",
    "                                        account_id_column=None):\n",
    "    \"\"\"\n",
    "    Calculate periodic Gini coefficients at multiple levels:\n",
    "    - Overall (entire dataset)\n",
    "    - By each individual segment (model version, trench, loan type, loan product type)\n",
    "    - By all possible combinations of segments\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with disbursement dates and score/label columns\n",
    "    score_column: name of the score column\n",
    "    label_column: name of the label column\n",
    "    namecolumn: name for the bad rate label\n",
    "    model_version_column: (optional) name of column for model version\n",
    "    trench_column: (optional) name of column for trench category\n",
    "    loan_type_column: (optional) name of loan type column\n",
    "    loan_product_type_column: (optional) name of loan product type column\n",
    "    account_id_column: (optional) name of column for distinct account IDs\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    required_columns = ['disbursementdate', score_column, label_column]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns. Need: {required_columns}\")\n",
    "    \n",
    "    optional_columns = {\n",
    "        'model_version': model_version_column,\n",
    "        'trench': trench_column,\n",
    "        'loan_type': loan_type_column,\n",
    "        'loan_product_type': loan_product_type_column,\n",
    "        'account_id': account_id_column\n",
    "    }\n",
    "    \n",
    "    for col_name, col in optional_columns.items():\n",
    "        if col and col not in df.columns:\n",
    "            raise ValueError(f\"{col_name.replace('_', ' ').title()} column '{col}' not found in dataframe\")\n",
    "    \n",
    "    # Create a copy to avoid modifying original dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date is datetime type\n",
    "    df['disbursementdate'] = pd.to_datetime(df['disbursementdate'])\n",
    "    \n",
    "    # Ensure score and label columns are numeric\n",
    "    df[score_column] = pd.to_numeric(df[score_column], errors='coerce')\n",
    "    df[label_column] = pd.to_numeric(df[label_column], errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid values\n",
    "    df = df.dropna(subset=[score_column, label_column])\n",
    "    \n",
    "    # Define list of datasets to process\n",
    "    datasets_to_process = [('Overall', df, {})]\n",
    "    \n",
    "    # Create list of available segment columns\n",
    "    segment_columns = []\n",
    "    if model_version_column:\n",
    "        segment_columns.append(('ModelVersion', model_version_column))\n",
    "    if trench_column:\n",
    "        segment_columns.append(('Trench', trench_column))\n",
    "    if loan_type_column:\n",
    "        segment_columns.append(('LoanType', loan_type_column))\n",
    "    if loan_product_type_column:\n",
    "        segment_columns.append(('ProductType', loan_product_type_column))\n",
    "    \n",
    "    # Generate all possible combinations of segment columns (from single to all)\n",
    "    for r in range(1, len(segment_columns) + 1):\n",
    "        for combo in combinations(segment_columns, r):\n",
    "            # Create combinations by iterating through all segment dimensions\n",
    "            def generate_combinations(df, segment_columns, index=0, current_filter=None, current_name=''):\n",
    "                if current_filter is None:\n",
    "                    current_filter = {}\n",
    "                \n",
    "                if index >= len(segment_columns):\n",
    "                    # Apply all filters and create segment\n",
    "                    filtered_df = df\n",
    "                    for col, val in current_filter.items():\n",
    "                        filtered_df = filtered_df[filtered_df[col] == val]\n",
    "                    \n",
    "                    if len(filtered_df) > 0:\n",
    "                        yield (current_name.strip('_'), filtered_df, current_filter.copy())\n",
    "                    return\n",
    "                \n",
    "                seg_name, seg_col = segment_columns[index]\n",
    "                for seg_value in sorted(df[seg_col].dropna().unique()):\n",
    "                    new_filter = current_filter.copy()\n",
    "                    new_filter[seg_col] = seg_value\n",
    "                    new_name = current_name + f'{seg_name}_{seg_value}_'\n",
    "                    \n",
    "                    yield from generate_combinations(df, segment_columns, index + 1, new_filter, new_name)\n",
    "            \n",
    "            for combo_name, combo_df, combo_metadata in generate_combinations(df, list(combo)):\n",
    "                datasets_to_process.append((combo_name, combo_df, combo_metadata))\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Process each dataset\n",
    "    for dataset_name, dataset_df, metadata in datasets_to_process:\n",
    "        # Calculate weekly Gini\n",
    "        dataset_df_copy = dataset_df.copy()\n",
    "        dataset_df_copy['week'] = dataset_df_copy['disbursementdate'].dt.to_period('W')\n",
    "        weekly_gini = dataset_df_copy.groupby('week').apply(\n",
    "            lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "            if len(x) >= 10 else np.nan\n",
    "        ).reset_index(name='gini')\n",
    "        weekly_gini['period'] = 'Week'\n",
    "        weekly_gini['start_date'] = weekly_gini['week'].apply(lambda x: x.to_timestamp())\n",
    "        weekly_gini['end_date'] = weekly_gini['start_date'] + timedelta(days=6)\n",
    "        \n",
    "        # Add distinct account count for weekly\n",
    "        if account_id_column:\n",
    "            weekly_account_counts = dataset_df_copy.groupby('week')[account_id_column].nunique().reset_index()\n",
    "            weekly_account_counts.columns = ['week', 'distinct_accounts']\n",
    "            weekly_gini = weekly_gini.merge(weekly_account_counts, on='week', how='left')\n",
    "        \n",
    "        weekly_gini = weekly_gini[['start_date', 'end_date', 'gini', 'period'] + (['distinct_accounts'] if account_id_column else [])]\n",
    "        \n",
    "        # Calculate monthly Gini\n",
    "        dataset_df_copy = dataset_df.copy()\n",
    "        dataset_df_copy['month'] = dataset_df_copy['disbursementdate'].dt.to_period('M')\n",
    "        monthly_gini = dataset_df_copy.groupby('month').apply(\n",
    "            lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "            if len(x) >= 20 else np.nan\n",
    "        ).reset_index(name='gini')\n",
    "        monthly_gini['period'] = 'Month'\n",
    "        monthly_gini['start_date'] = monthly_gini['month'].apply(lambda x: x.to_timestamp())\n",
    "        monthly_gini['end_date'] = monthly_gini['start_date'] + pd.DateOffset(months=1) - pd.Timedelta(days=1)\n",
    "        \n",
    "        # Add distinct account count for monthly\n",
    "        if account_id_column:\n",
    "            monthly_account_counts = dataset_df_copy.groupby('month')[account_id_column].nunique().reset_index()\n",
    "            monthly_account_counts.columns = ['month', 'distinct_accounts']\n",
    "            monthly_gini = monthly_gini.merge(monthly_account_counts, on='month', how='left')\n",
    "        \n",
    "        monthly_gini = monthly_gini[['start_date', 'end_date', 'gini', 'period'] + (['distinct_accounts'] if account_id_column else [])]\n",
    "        \n",
    "        # Combine results for this dataset\n",
    "        gini_results = pd.concat([weekly_gini, monthly_gini], ignore_index=True)\n",
    "        gini_results = gini_results.sort_values(by='start_date').reset_index(drop=True)\n",
    "        \n",
    "        # Add metadata columns\n",
    "        gini_results['Model_Name'] = score_column\n",
    "        gini_results['bad_rate'] = namecolumn\n",
    "        gini_results['segment_type'] = dataset_name\n",
    "        \n",
    "        # Add individual segment components\n",
    "        if model_version_column and model_version_column in metadata:\n",
    "            gini_results['model_version'] = metadata[model_version_column]\n",
    "        else:\n",
    "            gini_results['model_version'] = None\n",
    "        \n",
    "        if trench_column and trench_column in metadata:\n",
    "            gini_results['trench_category'] = metadata[trench_column]\n",
    "        else:\n",
    "            gini_results['trench_category'] = None\n",
    "        \n",
    "        if loan_type_column and loan_type_column in metadata:\n",
    "            gini_results['loan_type'] = metadata[loan_type_column]\n",
    "        else:\n",
    "            gini_results['loan_type'] = None\n",
    "        \n",
    "        if loan_product_type_column and loan_product_type_column in metadata:\n",
    "            gini_results['loan_product_type'] = metadata[loan_product_type_column]\n",
    "        else:\n",
    "            gini_results['loan_product_type'] = None\n",
    "        \n",
    "        gini_results.rename(columns={'gini': f'{score_column}_{namecolumn}_gini'}, inplace=True)\n",
    "        \n",
    "        all_results.append(gini_results)\n",
    "    \n",
    "    # Combine all results\n",
    "    final_results = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# gini_results = calculate_periodic_gini_prod_ver_trench_md(\n",
    "#     df_concat, \n",
    "#     'Alpha_cic_sil_score', \n",
    "#     'deffpd0', \n",
    "#     'FPD0',\n",
    "#     model_version_column='modelVersionId',\n",
    "#     trench_column='trenchCategory',\n",
    "#     loan_type_column='loan_type',\n",
    "#     loan_product_type_column='loan_product_type',\n",
    "#     account_id_column='digitalLoanAccountId'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1fa5650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from itertools import combinations\n",
    "\n",
    "def calculate_gini(scores, labels):\n",
    "    \"\"\"Calculate Gini coefficient\"\"\"\n",
    "    n = len(scores)\n",
    "    if n < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    sorted_indices = np.argsort(scores)\n",
    "    sorted_labels = labels.iloc[sorted_indices].values\n",
    "    cumsum_labels = np.cumsum(sorted_labels)\n",
    "    \n",
    "    gini = 1 - 2 * np.sum(cumsum_labels) / (n * np.sum(sorted_labels))\n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_periodic_gini_prod_ver_trench_md_col(df, score_column, label_column, namecolumn, \n",
    "                                        model_version_column=None, trench_column=None, \n",
    "                                        loan_type_column=None, loan_product_type_column=None,\n",
    "                                        account_id_column=None):\n",
    "    \"\"\"\n",
    "    Calculate periodic Gini coefficients at multiple levels (wide format):\n",
    "    - Overall (entire dataset)\n",
    "    - By each individual segment (model version, trench, loan type, loan product type)\n",
    "    - By all possible combinations of segments\n",
    "    \n",
    "    Returns wide format with one row per period and separate columns for each segment_type's Gini.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with disbursement dates and score/label columns\n",
    "    score_column: name of the score column\n",
    "    label_column: name of the label column\n",
    "    namecolumn: name for the bad rate label\n",
    "    model_version_column: (optional) name of column for model version\n",
    "    trench_column: (optional) name of column for trench category\n",
    "    loan_type_column: (optional) name of loan type column\n",
    "    loan_product_type_column: (optional) name of loan product type column\n",
    "    account_id_column: (optional) name of column for distinct account IDs\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    required_columns = ['disbursementdate', score_column, label_column]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns. Need: {required_columns}\")\n",
    "    \n",
    "    optional_columns = {\n",
    "        'model_version': model_version_column,\n",
    "        'trench': trench_column,\n",
    "        'loan_type': loan_type_column,\n",
    "        'loan_product_type': loan_product_type_column,\n",
    "        'account_id': account_id_column\n",
    "    }\n",
    "    \n",
    "    for col_name, col in optional_columns.items():\n",
    "        if col and col not in df.columns:\n",
    "            raise ValueError(f\"{col_name.replace('_', ' ').title()} column '{col}' not found in dataframe\")\n",
    "    \n",
    "    # Create a copy to avoid modifying original dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date is datetime type\n",
    "    df['disbursementdate'] = pd.to_datetime(df['disbursementdate'])\n",
    "    \n",
    "    # Ensure score and label columns are numeric\n",
    "    df[score_column] = pd.to_numeric(df[score_column], errors='coerce')\n",
    "    df[label_column] = pd.to_numeric(df[label_column], errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid values\n",
    "    df = df.dropna(subset=[score_column, label_column])\n",
    "    \n",
    "    # Define list of datasets to process\n",
    "    datasets_to_process = [('Overall', df, {})]\n",
    "    \n",
    "    # Create list of available segment columns\n",
    "    segment_columns = []\n",
    "    if model_version_column:\n",
    "        segment_columns.append(('ModelVersion', model_version_column))\n",
    "    if trench_column:\n",
    "        segment_columns.append(('Trench', trench_column))\n",
    "    if loan_type_column:\n",
    "        segment_columns.append(('LoanType', loan_type_column))\n",
    "    if loan_product_type_column:\n",
    "        segment_columns.append(('ProductType', loan_product_type_column))\n",
    "    \n",
    "    # Generate all possible combinations of segment columns (from single to all)\n",
    "    for r in range(1, len(segment_columns) + 1):\n",
    "        for combo in combinations(segment_columns, r):\n",
    "            # Create combinations by iterating through all segment dimensions\n",
    "            def generate_combinations(df, segment_columns, index=0, current_filter=None, current_name=''):\n",
    "                if current_filter is None:\n",
    "                    current_filter = {}\n",
    "                \n",
    "                if index >= len(segment_columns):\n",
    "                    # Apply all filters and create segment\n",
    "                    filtered_df = df\n",
    "                    for col, val in current_filter.items():\n",
    "                        filtered_df = filtered_df[filtered_df[col] == val]\n",
    "                    \n",
    "                    if len(filtered_df) > 0:\n",
    "                        yield (current_name.strip('_'), filtered_df, current_filter.copy())\n",
    "                    return\n",
    "                \n",
    "                seg_name, seg_col = segment_columns[index]\n",
    "                for seg_value in sorted(df[seg_col].dropna().unique()):\n",
    "                    new_filter = current_filter.copy()\n",
    "                    new_filter[seg_col] = seg_value\n",
    "                    new_name = current_name + f'{seg_name}_{seg_value}_'\n",
    "                    \n",
    "                    yield from generate_combinations(df, segment_columns, index + 1, new_filter, new_name)\n",
    "            \n",
    "            for combo_name, combo_df, combo_metadata in generate_combinations(df, list(combo)):\n",
    "                datasets_to_process.append((combo_name, combo_df, combo_metadata))\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Process each dataset\n",
    "    for dataset_name, dataset_df, metadata in datasets_to_process:\n",
    "        # Calculate weekly Gini\n",
    "        dataset_df_copy = dataset_df.copy()\n",
    "        dataset_df_copy['week'] = dataset_df_copy['disbursementdate'].dt.to_period('W')\n",
    "        weekly_gini = dataset_df_copy.groupby('week').apply(\n",
    "            lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "            if len(x) >= 10 else np.nan\n",
    "        ).reset_index(name='gini')\n",
    "        weekly_gini['period'] = 'Week'\n",
    "        weekly_gini['start_date'] = weekly_gini['week'].apply(lambda x: x.to_timestamp())\n",
    "        weekly_gini['end_date'] = weekly_gini['start_date'] + timedelta(days=6)\n",
    "        weekly_gini = weekly_gini[['start_date', 'end_date', 'gini', 'period']]\n",
    "        \n",
    "        # Calculate monthly Gini\n",
    "        dataset_df_copy = dataset_df.copy()\n",
    "        dataset_df_copy['month'] = dataset_df_copy['disbursementdate'].dt.to_period('M')\n",
    "        monthly_gini = dataset_df_copy.groupby('month').apply(\n",
    "            lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "            if len(x) >= 20 else np.nan\n",
    "        ).reset_index(name='gini')\n",
    "        monthly_gini['period'] = 'Month'\n",
    "        monthly_gini['start_date'] = monthly_gini['month'].apply(lambda x: x.to_timestamp())\n",
    "        monthly_gini['end_date'] = monthly_gini['start_date'] + pd.DateOffset(months=1) - pd.Timedelta(days=1)\n",
    "        monthly_gini = monthly_gini[['start_date', 'end_date', 'gini', 'period']]\n",
    "        \n",
    "        # Combine results for this dataset\n",
    "        gini_results = pd.concat([weekly_gini, monthly_gini], ignore_index=True)\n",
    "        gini_results = gini_results.sort_values(by='start_date').reset_index(drop=True)\n",
    "        \n",
    "        # Create column name for this segment's Gini\n",
    "        gini_column_name = f'{score_column}_{namecolumn}_gini_{dataset_name}'\n",
    "        gini_results[gini_column_name] = gini_results['gini']\n",
    "        gini_results = gini_results.drop('gini', axis=1)\n",
    "        \n",
    "        all_results.append(gini_results)\n",
    "    \n",
    "    # Merge all results on start_date, end_date, and period\n",
    "    final_results = all_results[0]\n",
    "    for result_df in all_results[1:]:\n",
    "        final_results = final_results.merge(\n",
    "            result_df,\n",
    "            on=['start_date', 'end_date', 'period'],\n",
    "            how='outer'\n",
    "        )\n",
    "    \n",
    "    # Add metadata columns (these will be the same for each row)\n",
    "    final_results['Model_Name'] = score_column\n",
    "    final_results['bad_rate'] = namecolumn\n",
    "    \n",
    "    if model_version_column:\n",
    "        final_results['model_version'] = None\n",
    "    else:\n",
    "        final_results['model_version'] = None\n",
    "    \n",
    "    if trench_column:\n",
    "        final_results['trench_category'] = None\n",
    "    else:\n",
    "        final_results['trench_category'] = None\n",
    "    \n",
    "    if loan_type_column:\n",
    "        final_results['loan_type'] = None\n",
    "    else:\n",
    "        final_results['loan_type'] = None\n",
    "    \n",
    "    if loan_product_type_column:\n",
    "        final_results['loan_product_type'] = None\n",
    "    else:\n",
    "        final_results['loan_product_type'] = None\n",
    "    \n",
    "    # Reorder columns: metadata first, then all Gini columns\n",
    "    metadata_cols = ['start_date', 'end_date', 'period', 'Model_Name', 'bad_rate', \n",
    "                     'model_version', 'trench_category', 'loan_type', 'loan_product_type']\n",
    "    gini_cols = [col for col in final_results.columns if col.startswith(f'{score_column}_{namecolumn}_gini_')]\n",
    "    \n",
    "    final_results = final_results[metadata_cols + gini_cols]\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# gini_results = calculate_periodic_gini_prod_ver_trench_md(\n",
    "#     df_concat, \n",
    "#     'Alpha_cic_sil_score', \n",
    "#     'deffpd0', \n",
    "#     'FPD0',\n",
    "#     model_version_column='modelVersionId',\n",
    "#     trench_column='trenchCategory',\n",
    "#     loan_type_column='loan_type',\n",
    "#     loan_product_type_column='loan_product_type',\n",
    "#     account_id_column='digitalLoanAccountId'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0e8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from itertools import combinations\n",
    "\n",
    "def calculate_gini(scores, labels):\n",
    "    \"\"\"Calculate Gini coefficient\"\"\"\n",
    "    n = len(scores)\n",
    "    if n < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    sorted_indices = np.argsort(scores)\n",
    "    sorted_labels = labels.iloc[sorted_indices].values\n",
    "    cumsum_labels = np.cumsum(sorted_labels)\n",
    "    \n",
    "    gini = 1 - 2 * np.sum(cumsum_labels) / (n * np.sum(sorted_labels))\n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_periodic_gini_prod_ver_trench_dimfact(df, score_column, label_column, namecolumn, \n",
    "                                        model_version_column=None, trench_column=None, \n",
    "                                        loan_type_column=None, loan_product_type_column=None,\n",
    "                                        account_id_column=None):\n",
    "    \"\"\"\n",
    "    Calculate periodic Gini coefficients and return Power BI-friendly long format\n",
    "    with fact and dimension tables.\n",
    "    \n",
    "    Returns:\n",
    "    - fact_table: Long format with one row per segment per period\n",
    "    - dimension_table: Unique segment combinations for filtering\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with disbursement dates and score/label columns\n",
    "    score_column: name of the score column\n",
    "    label_column: name of the label column\n",
    "    namecolumn: name for the bad rate label\n",
    "    model_version_column: (optional) name of column for model version\n",
    "    trench_column: (optional) name of column for trench category\n",
    "    loan_type_column: (optional) name of loan type column\n",
    "    loan_product_type_column: (optional) name of loan product type column\n",
    "    account_id_column: (optional) name of column for distinct account IDs\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    required_columns = ['disbursementdate', score_column, label_column]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns. Need: {required_columns}\")\n",
    "    \n",
    "    optional_columns = {\n",
    "        'model_version': model_version_column,\n",
    "        'trench': trench_column,\n",
    "        'loan_type': loan_type_column,\n",
    "        'loan_product_type': loan_product_type_column,\n",
    "        'account_id': account_id_column\n",
    "    }\n",
    "    \n",
    "    for col_name, col in optional_columns.items():\n",
    "        if col and col not in df.columns:\n",
    "            raise ValueError(f\"{col_name.replace('_', ' ').title()} column '{col}' not found in dataframe\")\n",
    "    \n",
    "    # Create a copy to avoid modifying original dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date is datetime type\n",
    "    df['disbursementdate'] = pd.to_datetime(df['disbursementdate'])\n",
    "    \n",
    "    # Ensure score and label columns are numeric\n",
    "    df[score_column] = pd.to_numeric(df[score_column], errors='coerce')\n",
    "    df[label_column] = pd.to_numeric(df[label_column], errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid values\n",
    "    df = df.dropna(subset=[score_column, label_column])\n",
    "    \n",
    "    # Define list of datasets to process\n",
    "    datasets_to_process = [('Overall', df, {})]\n",
    "    \n",
    "    # Create list of available segment columns\n",
    "    segment_columns = []\n",
    "    if model_version_column:\n",
    "        segment_columns.append(('ModelVersion', model_version_column))\n",
    "    if trench_column:\n",
    "        segment_columns.append(('Trench', trench_column))\n",
    "    if loan_type_column:\n",
    "        segment_columns.append(('LoanType', loan_type_column))\n",
    "    if loan_product_type_column:\n",
    "        segment_columns.append(('ProductType', loan_product_type_column))\n",
    "    \n",
    "    # Generate all possible combinations of segment columns\n",
    "    for r in range(1, len(segment_columns) + 1):\n",
    "        for combo in combinations(segment_columns, r):\n",
    "            def generate_combinations(df, segment_columns, index=0, current_filter=None, current_name=''):\n",
    "                if current_filter is None:\n",
    "                    current_filter = {}\n",
    "                \n",
    "                if index >= len(segment_columns):\n",
    "                    filtered_df = df\n",
    "                    for col, val in current_filter.items():\n",
    "                        filtered_df = filtered_df[filtered_df[col] == val]\n",
    "                    \n",
    "                    if len(filtered_df) > 0:\n",
    "                        yield (current_name.strip('_'), filtered_df, current_filter.copy())\n",
    "                    return\n",
    "                \n",
    "                seg_name, seg_col = segment_columns[index]\n",
    "                for seg_value in sorted(df[seg_col].dropna().unique()):\n",
    "                    new_filter = current_filter.copy()\n",
    "                    new_filter[seg_col] = seg_value\n",
    "                    new_name = current_name + f'{seg_name}_{seg_value}_'\n",
    "                    \n",
    "                    yield from generate_combinations(df, segment_columns, index + 1, new_filter, new_name)\n",
    "            \n",
    "            for combo_name, combo_df, combo_metadata in generate_combinations(df, list(combo)):\n",
    "                datasets_to_process.append((combo_name, combo_df, combo_metadata))\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Process each dataset\n",
    "    for dataset_name, dataset_df, metadata in datasets_to_process:\n",
    "        # Calculate weekly Gini\n",
    "        dataset_df_copy = dataset_df.copy()\n",
    "        dataset_df_copy['week'] = dataset_df_copy['disbursementdate'].dt.to_period('W')\n",
    "        weekly_gini = dataset_df_copy.groupby('week').apply(\n",
    "            lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "            if len(x) >= 10 else np.nan\n",
    "        ).reset_index(name='gini_value')\n",
    "        weekly_gini['period'] = 'Week'\n",
    "        weekly_gini['start_date'] = weekly_gini['week'].apply(lambda x: x.to_timestamp())\n",
    "        weekly_gini['end_date'] = weekly_gini['start_date'] + timedelta(days=6)\n",
    "        \n",
    "        # Add distinct account count for weekly\n",
    "        if account_id_column:\n",
    "            weekly_account_counts = dataset_df_copy.groupby('week')[account_id_column].nunique().reset_index()\n",
    "            weekly_account_counts.columns = ['week', 'distinct_accounts']\n",
    "            weekly_gini = weekly_gini.merge(weekly_account_counts, on='week', how='left')\n",
    "        else:\n",
    "            weekly_gini['distinct_accounts'] = None\n",
    "        \n",
    "        weekly_gini = weekly_gini[['start_date', 'end_date', 'gini_value', 'period', 'distinct_accounts']]\n",
    "        \n",
    "        # Calculate monthly Gini\n",
    "        dataset_df_copy = dataset_df.copy()\n",
    "        dataset_df_copy['month'] = dataset_df_copy['disbursementdate'].dt.to_period('M')\n",
    "        monthly_gini = dataset_df_copy.groupby('month').apply(\n",
    "            lambda x: calculate_gini(x[score_column], x[label_column])\n",
    "            if len(x) >= 20 else np.nan\n",
    "        ).reset_index(name='gini_value')\n",
    "        monthly_gini['period'] = 'Month'\n",
    "        monthly_gini['start_date'] = monthly_gini['month'].apply(lambda x: x.to_timestamp())\n",
    "        monthly_gini['end_date'] = monthly_gini['start_date'] + pd.DateOffset(months=1) - pd.Timedelta(days=1)\n",
    "        \n",
    "        # Add distinct account count for monthly\n",
    "        if account_id_column:\n",
    "            monthly_account_counts = dataset_df_copy.groupby('month')[account_id_column].nunique().reset_index()\n",
    "            monthly_account_counts.columns = ['month', 'distinct_accounts']\n",
    "            monthly_gini = monthly_gini.merge(monthly_account_counts, on='month', how='left')\n",
    "        else:\n",
    "            monthly_gini['distinct_accounts'] = None\n",
    "        \n",
    "        monthly_gini = monthly_gini[['start_date', 'end_date', 'gini_value', 'period', 'distinct_accounts']]\n",
    "        \n",
    "        # Combine results for this dataset\n",
    "        gini_results = pd.concat([weekly_gini, monthly_gini], ignore_index=True)\n",
    "        gini_results = gini_results.sort_values(by='start_date').reset_index(drop=True)\n",
    "        \n",
    "        # Add metadata columns\n",
    "        gini_results['Model_Name'] = score_column\n",
    "        gini_results['bad_rate'] = namecolumn\n",
    "        gini_results['segment_type'] = dataset_name\n",
    "        \n",
    "        # Add individual segment components\n",
    "        gini_results['model_version'] = metadata.get(model_version_column, None) if model_version_column else None\n",
    "        gini_results['trench_category'] = metadata.get(trench_column, None) if trench_column else None\n",
    "        gini_results['loan_type'] = metadata.get(loan_type_column, None) if loan_type_column else None\n",
    "        gini_results['loan_product_type'] = metadata.get(loan_product_type_column, None) if loan_product_type_column else None\n",
    "        \n",
    "        all_results.append(gini_results)\n",
    "    \n",
    "    # Combine all results\n",
    "    fact_table = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Create dimension table (unique segment combinations for filtering)\n",
    "    dimension_table = fact_table[['Model_Name', 'bad_rate', 'segment_type', 'model_version', \n",
    "                                   'trench_category', 'loan_type', 'loan_product_type']].drop_duplicates().reset_index(drop=True)\n",
    "    dimension_table['segment_id'] = range(len(dimension_table))\n",
    "    \n",
    "    # Add segment_id to fact table\n",
    "    fact_table = fact_table.merge(dimension_table[['segment_id', 'Model_Name', 'bad_rate', 'segment_type', \n",
    "                                                     'model_version', 'trench_category', 'loan_type', 'loan_product_type']], \n",
    "                                  on=['Model_Name', 'bad_rate', 'segment_type', 'model_version', \n",
    "                                      'trench_category', 'loan_type', 'loan_product_type'], \n",
    "                                  how='left')\n",
    "    \n",
    "    # Reorder columns in fact table\n",
    "    fact_table = fact_table[['segment_id', 'start_date', 'end_date', 'period', 'gini_value', 'distinct_accounts',\n",
    "                             'Model_Name', 'bad_rate', 'segment_type', 'model_version', 'trench_category', \n",
    "                             'loan_type', 'loan_product_type']]\n",
    "    \n",
    "    return fact_table, dimension_table\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# fact_table, dimension_table = calculate_periodic_gini_prod_ver_trench_md(\n",
    "#     df_concat, \n",
    "#     'Alpha_cic_sil_score', \n",
    "#     'deffpd0', \n",
    "#     'FPD0',\n",
    "#     model_version_column='modelVersionId',\n",
    "#     trench_column='trenchCategory',\n",
    "#     loan_type_column='loan_type',\n",
    "#     loan_product_type_column='loan_product_type',\n",
    "#     account_id_column='digitalLoanAccountId'\n",
    "# )\n",
    "# \n",
    "# # In Power BI:\n",
    "# # 1. Import fact_table and dimension_table\n",
    "# # 2. Create relationship: dimension_table[segment_id] -> fact_table[segment_id]\n",
    "# # 3. Use dimension table columns as filters\n",
    "# # 4. Create DAX measures:\n",
    "# #    - Gini Measure = AVERAGE(fact_table[gini_value])\n",
    "# #    - Account Count = SUM(fact_table[distinct_accounts])\n",
    "# # 5. Use start_date, end_date, period for time-based analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644dacf",
   "metadata": {},
   "source": [
    "# SIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12b3d8f",
   "metadata": {},
   "source": [
    "## FPD0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb420d97",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c432a912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataframe downloaded is:\t (48198, 15)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "customerId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "digitalLoanAccountId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "loanAccountNumber",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "modelDisplayName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Alpha_cic_sil_score",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "appln_submit_datetime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "disbursementdate",
         "rawType": "dbdate",
         "type": "unknown"
        },
        {
         "name": "Application_month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Data_selection",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "deffpd0",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "flg_mature_fpd0",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "new_loan_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "modelVersionId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trenchCategory",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "loan_product_type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "22ed2ec6-e240-47e4-a698-ed83596bb0a9",
       "rows": [
        [
         "0",
         "3676303",
         "044508eb-5e12-438c-b1ef-86a21ced7d1e",
         "60836763030011",
         "cic_model_sil",
         "0.04965601193365858",
         "2025-09-10 16:41:44",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL-Instore",
         "v1",
         "ALL",
         "Mall"
        ],
        [
         "1",
         "3676345",
         "0607f9c9-e3ba-49e4-9485-1acfa99ae525",
         "60836763450011",
         "cic_model_sil",
         "0.14804231980497298",
         "2025-09-10 16:23:25",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL Competitor",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "2",
         "3676152",
         "07edc892-0d41-439e-ad55-f8165c0427cc",
         "60836761520013",
         "cic_model_sil",
         "0.07974516024873278",
         "2025-09-10 15:36:01",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL Competitor",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "3",
         "3676262",
         "4281cbb6-49de-429f-9c53-f4344003c6b7",
         "60836762620018",
         "cic_model_sil",
         "0.11136085020144332",
         "2025-09-10 15:58:54",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL Competitor",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "4",
         "3676302",
         "4e405e33-5b05-4955-97e5-10722dbf2fd3",
         "60836763020019",
         "cic_model_sil",
         "0.11104678305795064",
         "2025-09-10 16:12:22",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL-Instore",
         "v1",
         "ALL",
         "Appliance"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerId</th>\n",
       "      <th>digitalLoanAccountId</th>\n",
       "      <th>loanAccountNumber</th>\n",
       "      <th>modelDisplayName</th>\n",
       "      <th>Alpha_cic_sil_score</th>\n",
       "      <th>appln_submit_datetime</th>\n",
       "      <th>disbursementdate</th>\n",
       "      <th>Application_month</th>\n",
       "      <th>Data_selection</th>\n",
       "      <th>deffpd0</th>\n",
       "      <th>flg_mature_fpd0</th>\n",
       "      <th>new_loan_type</th>\n",
       "      <th>modelVersionId</th>\n",
       "      <th>trenchCategory</th>\n",
       "      <th>loan_product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3676303</td>\n",
       "      <td>044508eb-5e12-438c-b1ef-86a21ced7d1e</td>\n",
       "      <td>60836763030011</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.04965601193365858</td>\n",
       "      <td>2025-09-10 16:41:44</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL-Instore</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Mall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3676345</td>\n",
       "      <td>0607f9c9-e3ba-49e4-9485-1acfa99ae525</td>\n",
       "      <td>60836763450011</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.14804231980497298</td>\n",
       "      <td>2025-09-10 16:23:25</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL Competitor</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3676152</td>\n",
       "      <td>07edc892-0d41-439e-ad55-f8165c0427cc</td>\n",
       "      <td>60836761520013</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.07974516024873278</td>\n",
       "      <td>2025-09-10 15:36:01</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL Competitor</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3676262</td>\n",
       "      <td>4281cbb6-49de-429f-9c53-f4344003c6b7</td>\n",
       "      <td>60836762620018</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.11136085020144332</td>\n",
       "      <td>2025-09-10 15:58:54</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL Competitor</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3676302</td>\n",
       "      <td>4e405e33-5b05-4955-97e5-10722dbf2fd3</td>\n",
       "      <td>60836763020019</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.11104678305795064</td>\n",
       "      <td>2025-09-10 16:12:22</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL-Instore</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customerId                  digitalLoanAccountId loanAccountNumber  \\\n",
       "0    3676303  044508eb-5e12-438c-b1ef-86a21ced7d1e    60836763030011   \n",
       "1    3676345  0607f9c9-e3ba-49e4-9485-1acfa99ae525    60836763450011   \n",
       "2    3676152  07edc892-0d41-439e-ad55-f8165c0427cc    60836761520013   \n",
       "3    3676262  4281cbb6-49de-429f-9c53-f4344003c6b7    60836762620018   \n",
       "4    3676302  4e405e33-5b05-4955-97e5-10722dbf2fd3    60836763020019   \n",
       "\n",
       "  modelDisplayName  Alpha_cic_sil_score appln_submit_datetime  \\\n",
       "0    cic_model_sil  0.04965601193365858   2025-09-10 16:41:44   \n",
       "1    cic_model_sil  0.14804231980497298   2025-09-10 16:23:25   \n",
       "2    cic_model_sil  0.07974516024873278   2025-09-10 15:36:01   \n",
       "3    cic_model_sil  0.11136085020144332   2025-09-10 15:58:54   \n",
       "4    cic_model_sil  0.11104678305795064   2025-09-10 16:12:22   \n",
       "\n",
       "  disbursementdate Application_month Data_selection  deffpd0  flg_mature_fpd0  \\\n",
       "0       2025-09-10           2025-09           Test        0                1   \n",
       "1       2025-09-10           2025-09           Test        0                1   \n",
       "2       2025-09-10           2025-09           Test        0                1   \n",
       "3       2025-09-10           2025-09           Test        0                1   \n",
       "4       2025-09-10           2025-09           Test        0                1   \n",
       "\n",
       "    new_loan_type modelVersionId trenchCategory loan_product_type  \n",
       "0     SIL-Instore             v1            ALL              Mall  \n",
       "1  SIL Competitor             v1            ALL         Appliance  \n",
       "2  SIL Competitor             v1            ALL         Appliance  \n",
       "3  SIL Competitor             v1            ALL         Appliance  \n",
       "4     SIL-Instore             v1            ALL         Appliance  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq = \"\"\" \n",
    "with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL'\n",
    "         when trenchCategory = '' then 'ALL'\n",
    "         else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.audit_balance.ml_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as \n",
    "  (select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Test' Data_selection,  \n",
    "  deffpd0,\n",
    "  flg_mature_fpd0,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId, trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "  from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "   left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and flg_mature_fpd0 = 1\n",
    "  )\n",
    "  select *  from base\n",
    "  ;\n",
    "\"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf4f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad94f7",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa4d546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataframe downloaded is:\t (292181, 15)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "customerId",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "digitalLoanAccountId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "loanAccountNumber",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "modelDisplayName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Alpha_cic_sil_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "appln_submit_datetime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "disbursementdate",
         "rawType": "dbdate",
         "type": "unknown"
        },
        {
         "name": "Application_month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Data_selection",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "deffpd0",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "flg_mature_fpd0",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "new_loan_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "modelVersionId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trenchCategory",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "loan_product_type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "20801881-202c-40dd-a2b3-d7431110a791",
       "rows": [
        [
         "0",
         "2394977",
         "b74071a9-2f14-4e55-9bc5-cbfcb7344c5a",
         "60823949770013",
         "Alpha - CIC-SIL-Model",
         "0.10831719555647866",
         "2024-02-09 16:42:24",
         "2024-02-09",
         "2024-02",
         "Train",
         "0",
         "1",
         "SIL-Instore",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "1",
         "2393585",
         "af1763b6-3754-4b46-9ccc-4a3908ca68cb",
         "60823935850017",
         "Alpha - CIC-SIL-Model",
         "0.11710003177107081",
         "2024-02-08 12:18:12",
         "2024-02-08",
         "2024-02",
         "Train",
         "1",
         "1",
         "SIL-Instore",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "2",
         "2117667",
         "e7a1ab7a-242b-41bf-8845-c5a0a257515a",
         "60821176670012",
         "Alpha - CIC-SIL-Model",
         "0.16565982037237875",
         "2023-10-27 20:07:24",
         "2023-10-27",
         "2023-10",
         "Train",
         "0",
         "1",
         "SIL-Instore",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "3",
         "2254093",
         "e0a87777-f74b-4706-a3e3-51d461366b13",
         "60822540930011",
         "Alpha - CIC-SIL-Model",
         "0.16188082855336533",
         "2023-09-30 17:24:32",
         "2023-09-30",
         "2023-09",
         "Train",
         "0",
         "1",
         "SIL-Instore",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "4",
         "2388357",
         "81a58864-e04c-4055-a4b6-65e361c06f0e",
         "60823883570012",
         "Alpha - CIC-SIL-Model",
         "0.1251328756722129",
         "2024-02-03 11:01:47",
         "2024-02-03",
         "2024-02",
         "Train",
         "1",
         "1",
         "SIL-Instore",
         "v1",
         "ALL",
         "Appliance"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerId</th>\n",
       "      <th>digitalLoanAccountId</th>\n",
       "      <th>loanAccountNumber</th>\n",
       "      <th>modelDisplayName</th>\n",
       "      <th>Alpha_cic_sil_score</th>\n",
       "      <th>appln_submit_datetime</th>\n",
       "      <th>disbursementdate</th>\n",
       "      <th>Application_month</th>\n",
       "      <th>Data_selection</th>\n",
       "      <th>deffpd0</th>\n",
       "      <th>flg_mature_fpd0</th>\n",
       "      <th>new_loan_type</th>\n",
       "      <th>modelVersionId</th>\n",
       "      <th>trenchCategory</th>\n",
       "      <th>loan_product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2394977</td>\n",
       "      <td>b74071a9-2f14-4e55-9bc5-cbfcb7344c5a</td>\n",
       "      <td>60823949770013</td>\n",
       "      <td>Alpha - CIC-SIL-Model</td>\n",
       "      <td>0.108317</td>\n",
       "      <td>2024-02-09 16:42:24</td>\n",
       "      <td>2024-02-09</td>\n",
       "      <td>2024-02</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL-Instore</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2393585</td>\n",
       "      <td>af1763b6-3754-4b46-9ccc-4a3908ca68cb</td>\n",
       "      <td>60823935850017</td>\n",
       "      <td>Alpha - CIC-SIL-Model</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>2024-02-08 12:18:12</td>\n",
       "      <td>2024-02-08</td>\n",
       "      <td>2024-02</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL-Instore</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2117667</td>\n",
       "      <td>e7a1ab7a-242b-41bf-8845-c5a0a257515a</td>\n",
       "      <td>60821176670012</td>\n",
       "      <td>Alpha - CIC-SIL-Model</td>\n",
       "      <td>0.165660</td>\n",
       "      <td>2023-10-27 20:07:24</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023-10</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL-Instore</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254093</td>\n",
       "      <td>e0a87777-f74b-4706-a3e3-51d461366b13</td>\n",
       "      <td>60822540930011</td>\n",
       "      <td>Alpha - CIC-SIL-Model</td>\n",
       "      <td>0.161881</td>\n",
       "      <td>2023-09-30 17:24:32</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>2023-09</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL-Instore</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2388357</td>\n",
       "      <td>81a58864-e04c-4055-a4b6-65e361c06f0e</td>\n",
       "      <td>60823883570012</td>\n",
       "      <td>Alpha - CIC-SIL-Model</td>\n",
       "      <td>0.125133</td>\n",
       "      <td>2024-02-03 11:01:47</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-02</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL-Instore</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerId                  digitalLoanAccountId loanAccountNumber  \\\n",
       "0     2394977  b74071a9-2f14-4e55-9bc5-cbfcb7344c5a    60823949770013   \n",
       "1     2393585  af1763b6-3754-4b46-9ccc-4a3908ca68cb    60823935850017   \n",
       "2     2117667  e7a1ab7a-242b-41bf-8845-c5a0a257515a    60821176670012   \n",
       "3     2254093  e0a87777-f74b-4706-a3e3-51d461366b13    60822540930011   \n",
       "4     2388357  81a58864-e04c-4055-a4b6-65e361c06f0e    60823883570012   \n",
       "\n",
       "        modelDisplayName  Alpha_cic_sil_score appln_submit_datetime  \\\n",
       "0  Alpha - CIC-SIL-Model             0.108317   2024-02-09 16:42:24   \n",
       "1  Alpha - CIC-SIL-Model             0.117100   2024-02-08 12:18:12   \n",
       "2  Alpha - CIC-SIL-Model             0.165660   2023-10-27 20:07:24   \n",
       "3  Alpha - CIC-SIL-Model             0.161881   2023-09-30 17:24:32   \n",
       "4  Alpha - CIC-SIL-Model             0.125133   2024-02-03 11:01:47   \n",
       "\n",
       "  disbursementdate Application_month Data_selection  deffpd0  flg_mature_fpd0  \\\n",
       "0       2024-02-09           2024-02          Train        0                1   \n",
       "1       2024-02-08           2024-02          Train        1                1   \n",
       "2       2023-10-27           2023-10          Train        0                1   \n",
       "3       2023-09-30           2023-09          Train        0                1   \n",
       "4       2024-02-03           2024-02          Train        1                1   \n",
       "\n",
       "  new_loan_type modelVersionId trenchCategory loan_product_type  \n",
       "0   SIL-Instore             v1            ALL         Appliance  \n",
       "1   SIL-Instore             v1            ALL         Appliance  \n",
       "2   SIL-Instore             v1            ALL         Appliance  \n",
       "3   SIL-Instore             v1            ALL         Appliance  \n",
       "4   SIL-Instore             v1            ALL         Appliance  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq = \"\"\" \n",
    "  with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL' \n",
    "        when trenchCategory = ''then 'ALL' \n",
    "        else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.dap_ds_poweruser_playground.ml_training_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as\n",
    "(select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Train' Data_selection,  \n",
    "    deffpd0,\n",
    "  flg_mature_fpd0,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId,\n",
    "    trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "    from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "  left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and flg_mature_fpd0 = 1\n",
    "  )\n",
    "  select * from base;\n",
    "  \"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef5d28de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a21733f",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d5a4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the concatenated dataframe is:\t (340379, 15)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "customerId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "digitalLoanAccountId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "loanAccountNumber",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "modelDisplayName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Alpha_cic_sil_score",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "appln_submit_datetime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "disbursementdate",
         "rawType": "dbdate",
         "type": "unknown"
        },
        {
         "name": "Application_month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Data_selection",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "deffpd0",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "flg_mature_fpd0",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "new_loan_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "modelVersionId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trenchCategory",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "loan_product_type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "94260147-ec59-4fc2-beeb-f1f651ea335d",
       "rows": [
        [
         "0",
         "3676303",
         "044508eb-5e12-438c-b1ef-86a21ced7d1e",
         "60836763030011",
         "cic_model_sil",
         "0.04965601193365858",
         "2025-09-10 16:41:44",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL-Instore",
         "v1",
         "ALL",
         "Mall"
        ],
        [
         "1",
         "3676345",
         "0607f9c9-e3ba-49e4-9485-1acfa99ae525",
         "60836763450011",
         "cic_model_sil",
         "0.14804231980497298",
         "2025-09-10 16:23:25",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL Competitor",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "2",
         "3676152",
         "07edc892-0d41-439e-ad55-f8165c0427cc",
         "60836761520013",
         "cic_model_sil",
         "0.07974516024873278",
         "2025-09-10 15:36:01",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL Competitor",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "3",
         "3676262",
         "4281cbb6-49de-429f-9c53-f4344003c6b7",
         "60836762620018",
         "cic_model_sil",
         "0.11136085020144332",
         "2025-09-10 15:58:54",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL Competitor",
         "v1",
         "ALL",
         "Appliance"
        ],
        [
         "4",
         "3676302",
         "4e405e33-5b05-4955-97e5-10722dbf2fd3",
         "60836763020019",
         "cic_model_sil",
         "0.11104678305795064",
         "2025-09-10 16:12:22",
         "2025-09-10",
         "2025-09",
         "Test",
         "0",
         "1",
         "SIL-Instore",
         "v1",
         "ALL",
         "Appliance"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerId</th>\n",
       "      <th>digitalLoanAccountId</th>\n",
       "      <th>loanAccountNumber</th>\n",
       "      <th>modelDisplayName</th>\n",
       "      <th>Alpha_cic_sil_score</th>\n",
       "      <th>appln_submit_datetime</th>\n",
       "      <th>disbursementdate</th>\n",
       "      <th>Application_month</th>\n",
       "      <th>Data_selection</th>\n",
       "      <th>deffpd0</th>\n",
       "      <th>flg_mature_fpd0</th>\n",
       "      <th>new_loan_type</th>\n",
       "      <th>modelVersionId</th>\n",
       "      <th>trenchCategory</th>\n",
       "      <th>loan_product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3676303</td>\n",
       "      <td>044508eb-5e12-438c-b1ef-86a21ced7d1e</td>\n",
       "      <td>60836763030011</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.04965601193365858</td>\n",
       "      <td>2025-09-10 16:41:44</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL-Instore</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Mall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3676345</td>\n",
       "      <td>0607f9c9-e3ba-49e4-9485-1acfa99ae525</td>\n",
       "      <td>60836763450011</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.14804231980497298</td>\n",
       "      <td>2025-09-10 16:23:25</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL Competitor</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3676152</td>\n",
       "      <td>07edc892-0d41-439e-ad55-f8165c0427cc</td>\n",
       "      <td>60836761520013</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.07974516024873278</td>\n",
       "      <td>2025-09-10 15:36:01</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL Competitor</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3676262</td>\n",
       "      <td>4281cbb6-49de-429f-9c53-f4344003c6b7</td>\n",
       "      <td>60836762620018</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.11136085020144332</td>\n",
       "      <td>2025-09-10 15:58:54</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL Competitor</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3676302</td>\n",
       "      <td>4e405e33-5b05-4955-97e5-10722dbf2fd3</td>\n",
       "      <td>60836763020019</td>\n",
       "      <td>cic_model_sil</td>\n",
       "      <td>0.11104678305795064</td>\n",
       "      <td>2025-09-10 16:12:22</td>\n",
       "      <td>2025-09-10</td>\n",
       "      <td>2025-09</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SIL-Instore</td>\n",
       "      <td>v1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Appliance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customerId                  digitalLoanAccountId loanAccountNumber  \\\n",
       "0    3676303  044508eb-5e12-438c-b1ef-86a21ced7d1e    60836763030011   \n",
       "1    3676345  0607f9c9-e3ba-49e4-9485-1acfa99ae525    60836763450011   \n",
       "2    3676152  07edc892-0d41-439e-ad55-f8165c0427cc    60836761520013   \n",
       "3    3676262  4281cbb6-49de-429f-9c53-f4344003c6b7    60836762620018   \n",
       "4    3676302  4e405e33-5b05-4955-97e5-10722dbf2fd3    60836763020019   \n",
       "\n",
       "  modelDisplayName  Alpha_cic_sil_score appln_submit_datetime  \\\n",
       "0    cic_model_sil  0.04965601193365858   2025-09-10 16:41:44   \n",
       "1    cic_model_sil  0.14804231980497298   2025-09-10 16:23:25   \n",
       "2    cic_model_sil  0.07974516024873278   2025-09-10 15:36:01   \n",
       "3    cic_model_sil  0.11136085020144332   2025-09-10 15:58:54   \n",
       "4    cic_model_sil  0.11104678305795064   2025-09-10 16:12:22   \n",
       "\n",
       "  disbursementdate Application_month Data_selection  deffpd0  flg_mature_fpd0  \\\n",
       "0       2025-09-10           2025-09           Test        0                1   \n",
       "1       2025-09-10           2025-09           Test        0                1   \n",
       "2       2025-09-10           2025-09           Test        0                1   \n",
       "3       2025-09-10           2025-09           Test        0                1   \n",
       "4       2025-09-10           2025-09           Test        0                1   \n",
       "\n",
       "    new_loan_type modelVersionId trenchCategory loan_product_type  \n",
       "0     SIL-Instore             v1            ALL              Mall  \n",
       "1  SIL Competitor             v1            ALL         Appliance  \n",
       "2  SIL Competitor             v1            ALL         Appliance  \n",
       "3  SIL Competitor             v1            ALL         Appliance  \n",
       "4     SIL-Instore             v1            ALL         Appliance  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(f\"The shape of the concatenated dataframe is:\\t {df_concat.shape}\")\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e99ee18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customerId', 'digitalLoanAccountId', 'loanAccountNumber',\n",
       "       'modelDisplayName', 'Alpha_cic_sil_score', 'appln_submit_datetime',\n",
       "       'disbursementdate', 'Application_month', 'Data_selection', 'deffpd0',\n",
       "       'flg_mature_fpd0', 'new_loan_type', 'modelVersionId', 'trenchCategory',\n",
       "       'loan_product_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d97b63dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('Data_selection', 'new_loan_type', 'modelVersionId', 'loan_product_type')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "digitalLoanAccountId",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ce2e4a6b-6e20-490f-a05a-cee7f3d756c8",
       "rows": [
        [
         "('Test', 'SIL Competitor', 'v1', 'Appliance')",
         "14107"
        ],
        [
         "('Test', 'SIL Competitor', 'v1', 'Mall')",
         "4679"
        ],
        [
         "('Test', 'SIL ZERO', 'v1', 'Appliance')",
         "2005"
        ],
        [
         "('Test', 'SIL-Instore', 'v1', 'Appliance')",
         "22617"
        ],
        [
         "('Test', 'SIL-Instore', 'v1', 'Mall')",
         "4790"
        ],
        [
         "('Train', 'SIL Competitor', 'v1', 'Appliance')",
         "4595"
        ],
        [
         "('Train', 'SIL Competitor', 'v1', 'Mall')",
         "1104"
        ],
        [
         "('Train', 'SIL Competitor', 'v1', 'Mobile')",
         "45"
        ],
        [
         "('Train', 'SIL Competitor', 'v2', 'Appliance')",
         "27940"
        ],
        [
         "('Train', 'SIL Competitor', 'v2', 'Mall')",
         "8153"
        ],
        [
         "('Train', 'SIL Competitor', 'v2', 'Mobile')",
         "45"
        ],
        [
         "('Train', 'SIL Repeat', 'v1', 'Appliance')",
         "1224"
        ],
        [
         "('Train', 'SIL Repeat', 'v1', 'Mall')",
         "129"
        ],
        [
         "('Train', 'SIL ZERO', 'v1', 'Appliance')",
         "5465"
        ],
        [
         "('Train', 'SIL ZERO', 'v1', 'Mobile')",
         "924"
        ],
        [
         "('Train', 'SIL ZERO', 'v2', 'Appliance')",
         "9275"
        ],
        [
         "('Train', 'SIL ZERO', 'v2', 'Mobile')",
         "544"
        ],
        [
         "('Train', 'SIL-Instore', 'v1', 'Appliance')",
         "96954"
        ],
        [
         "('Train', 'SIL-Instore', 'v1', 'Mall')",
         "5771"
        ],
        [
         "('Train', 'SIL-Instore', 'v1', 'Mobile')",
         "16616"
        ],
        [
         "('Train', 'SIL-Instore', 'v2', 'Appliance')",
         "90985"
        ],
        [
         "('Train', 'SIL-Instore', 'v2', 'Mall')",
         "12853"
        ],
        [
         "('Train', 'SIL-Instore', 'v2', 'Mobile')",
         "9559"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 23
       }
      },
      "text/plain": [
       "Data_selection  new_loan_type   modelVersionId  loan_product_type\n",
       "Test            SIL Competitor  v1              Appliance            14107\n",
       "                                                Mall                  4679\n",
       "                SIL ZERO        v1              Appliance             2005\n",
       "                SIL-Instore     v1              Appliance            22617\n",
       "                                                Mall                  4790\n",
       "Train           SIL Competitor  v1              Appliance             4595\n",
       "                                                Mall                  1104\n",
       "                                                Mobile                  45\n",
       "                                v2              Appliance            27940\n",
       "                                                Mall                  8153\n",
       "                                                Mobile                  45\n",
       "                SIL Repeat      v1              Appliance             1224\n",
       "                                                Mall                   129\n",
       "                SIL ZERO        v1              Appliance             5465\n",
       "                                                Mobile                 924\n",
       "                                v2              Appliance             9275\n",
       "                                                Mobile                 544\n",
       "                SIL-Instore     v1              Appliance            96954\n",
       "                                                Mall                  5771\n",
       "                                                Mobile               16616\n",
       "                                v2              Appliance            90985\n",
       "                                                Mall                 12853\n",
       "                                                Mobile                9559\n",
       "Name: digitalLoanAccountId, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.groupby(['Data_selection','new_loan_type', 'modelVersionId', 'loan_product_type'])['digitalLoanAccountId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a2d8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SIL-Instore', 'SIL Competitor', 'SIL ZERO', 'SIL Repeat'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat['new_loan_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af293927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv(r\"D:\\OneDrive - Tonik Financial Pte Ltd\\MyStuff\\Data Engineering\\Model_Monitoring\\Gini Monitoring\\New_Gini_Monitoring_2025-11-25\\Future\\sample.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table, dimension_table = calculate_periodic_gini_prod_ver_trench_dimfact(\n",
    "    df_concat, \n",
    "    'Alpha_cic_sil_score', \n",
    "    'deffpd0', \n",
    "    'FPD0',\n",
    "    model_version_column='modelVersionId',\n",
    "    trench_column='trenchCategory',\n",
    "    loan_type_column='new_loan_type',\n",
    "    loan_product_type_column='loan_product_type',\n",
    "    account_id_column='digitalLoanAccountId'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fact_table.columns)\n",
    "fact_table['segment_type'].value_counts(dropna=False)\n",
    "fact_table['Model_display_name'] = 'cic_model_sil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table[fact_table['loan_product_type'].isnull()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_table['Model_display_name'] = 'cic_model_sil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to BigQuery\n",
    "table_id = \"prj-prod-dataplatform.dap_ds_poweruser_playground.fact_table\"\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=\"WRITE_TRUNCATE\",  # or \"WRITE_APPEND\"\n",
    ")\n",
    "job = client.load_table_from_dataframe(fact_table, table_id, job_config=job_config)\n",
    "job.result()  # Wait for the job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to BigQuery\n",
    "table_id = \"prj-prod-dataplatform.dap_ds_poweruser_playground.dimension_table\"\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=\"WRITE_TRUNCATE\",  # or \"WRITE_APPEND\"\n",
    ")\n",
    "job = client.load_table_from_dataframe(dimension_table, table_id, job_config=job_config)\n",
    "job.result()  # Wait for the job to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a72766",
   "metadata": {},
   "source": [
    "## FPD10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6d2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73bbea51",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = \"\"\" \n",
    "with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL'\n",
    "         when trenchCategory = '' then 'ALL'\n",
    "         else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.audit_balance.ml_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as \n",
    "  (select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Test' Data_selection,  \n",
    "  deffpd10,\n",
    "  flg_mature_fpd10,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId, trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "  from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "   left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and flg_mature_fpd10 = 1\n",
    "  )\n",
    "  select *  from base\n",
    "  ;\n",
    "\"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c891c2",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ad9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = \"\"\" \n",
    "  with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL' \n",
    "        when trenchCategory = ''then 'ALL' \n",
    "        else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.dap_ds_poweruser_playground.ml_training_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as\n",
    "(select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Train' Data_selection,  \n",
    "    del.deffpd10,\n",
    "  del.flg_mature_fpd10,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId,\n",
    "    trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "    from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "  left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and del.flg_mature_fpd10 = 1\n",
    "  )\n",
    "  select * from base;\n",
    "  \"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d687eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec8102",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(f\"The shape of the concatenated dataframe is:\\t {df_concat.shape}\")\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat.to_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177393cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.groupby(['Data_selection','new_loan_type', 'modelVersionId', 'loan_product_type'])['digitalLoanAccountId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a114234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_results = calculate_periodic_gini_prod_ver_trench_md_col(\n",
    "    df_concat, \n",
    "    'Alpha_cic_sil_score', \n",
    "    'deffpd10', \n",
    "    'FPD10',\n",
    "    model_version_column='modelVersionId',\n",
    "    trench_column='trenchCategory',\n",
    "    loan_type_column='new_loan_type',\n",
    "    loan_product_type_column='loan_product_type',\n",
    "    account_id_column='digitalLoanAccountId'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b507a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the Gini results dataframe is:\\t {gini_results.shape}\")\n",
    "gini_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = gini_results.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46139fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b95d61d0",
   "metadata": {},
   "source": [
    "## FPD30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422a379",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = \"\"\" \n",
    "with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL'\n",
    "         when trenchCategory = '' then 'ALL'\n",
    "         else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.audit_balance.ml_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as \n",
    "  (select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Test' Data_selection,  \n",
    "  del.deffpd30,\n",
    "  del.flg_mature_fpd30,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId, trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "  from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "   left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and flg_mature_fpd30 = 1\n",
    "  )\n",
    "  select *  from base\n",
    "  ;\n",
    "\"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a5b297",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = \"\"\" \n",
    "  with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL' \n",
    "        when trenchCategory = ''then 'ALL' \n",
    "        else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.dap_ds_poweruser_playground.ml_training_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as\n",
    "(select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Train' Data_selection,  \n",
    "    del.deffpd30,\n",
    "  del.flg_mature_fpd30,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId,\n",
    "    trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "    from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "  left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and del.flg_mature_fpd30 = 1\n",
    "  )\n",
    "  select * from base;\n",
    "  \"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40b335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d4d22",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(f\"The shape of the concatenated dataframe is:\\t {df_concat.shape}\")\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat.to_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac00ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.groupby(['Data_selection','new_loan_type', 'modelVersionId', 'loan_product_type'])['digitalLoanAccountId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee73b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_results = calculate_periodic_gini_prod_ver_trench_md_col(\n",
    "    df_concat, \n",
    "    'Alpha_cic_sil_score', \n",
    "    'deffpd30', \n",
    "    'FPD30',\n",
    "    model_version_column='modelVersionId',\n",
    "    trench_column='trenchCategory',\n",
    "    loan_type_column='new_loan_type',\n",
    "    loan_product_type_column='loan_product_type',\n",
    "    account_id_column='digitalLoanAccountId'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the Gini results dataframe is:\\t {gini_results.shape}\")\n",
    "gini_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = gini_results.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb3c100",
   "metadata": {},
   "source": [
    "## FSPD30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f8992",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = \"\"\" \n",
    "with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL'\n",
    "         when trenchCategory = '' then 'ALL'\n",
    "         else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.audit_balance.ml_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as \n",
    "  (select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Test' Data_selection,  \n",
    "  del.deffspd30,\n",
    "  del.flg_mature_fspd_30,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId, trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "  from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "   left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and del.flg_mature_fspd_30 = 1\n",
    "  )\n",
    "  select *  from base\n",
    "  ;\n",
    "\"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317463e2",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = \"\"\" \n",
    "  with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL' \n",
    "        when trenchCategory = ''then 'ALL' \n",
    "        else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.dap_ds_poweruser_playground.ml_training_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as\n",
    "(select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Train' Data_selection,  \n",
    "    del.deffspd30,\n",
    "  del.flg_mature_fspd_30,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId,\n",
    "    trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "    from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "  left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and del.flg_mature_fspd_30 = 1\n",
    "  )\n",
    "  select * from base;\n",
    "  \"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c341c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06cf2d",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e165828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(f\"The shape of the concatenated dataframe is:\\t {df_concat.shape}\")\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat.to_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.groupby(['Data_selection','new_loan_type', 'modelVersionId', 'loan_product_type'])['digitalLoanAccountId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_results = calculate_periodic_gini_prod_ver_trench_md_col(\n",
    "    df_concat, \n",
    "    'Alpha_cic_sil_score', \n",
    "    'deffspd30', \n",
    "    'FSPD30',\n",
    "    model_version_column='modelVersionId',\n",
    "    trench_column='trenchCategory',\n",
    "    loan_type_column='new_loan_type',\n",
    "    loan_product_type_column='loan_product_type',\n",
    "    account_id_column='digitalLoanAccountId'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af291a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the Gini results dataframe is:\\t {gini_results.shape}\")\n",
    "gini_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b226e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = gini_results.copy()\n",
    "f3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b55f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11595ecd",
   "metadata": {},
   "source": [
    "## FSTPD30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296f6f0",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b896d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = \"\"\" \n",
    "with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL'\n",
    "         when trenchCategory = '' then 'ALL'\n",
    "         else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.audit_balance.ml_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as \n",
    "  (select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Test' Data_selection,  \n",
    "  del.deffstpd30,\n",
    "  del.flg_mature_fstpd_30,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId, trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "  from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "   left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and del.flg_mature_fstpd_30 = 1\n",
    "  )\n",
    "  select *  from base\n",
    "  ;\n",
    "\"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55358e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69870679",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = \"\"\" \n",
    "  with modelname as \n",
    "  (SELECT\n",
    "    customerId,digitalLoanAccountId,prediction Alpha_cic_sil_score,start_time,end_time,modelDisplayName,modelVersionId, \n",
    "    case when trenchCategory is null then 'ALL' \n",
    "        when trenchCategory = ''then 'ALL' \n",
    "        else trenchCategory end as trenchCategory,\n",
    "    REPLACE(REPLACE(calcFeature, \"'\", '\"'), \"None\", \"null\") AS calcFeature\n",
    "  FROM prj-prod-dataplatform.dap_ds_poweruser_playground.ml_training_model_run_details\n",
    "  WHERE modelDisplayName in ('Alpha - CIC-SIL-Model', 'cic_model_sil', 'Sil-Alpha-CIC-SIL-Model')\n",
    "  ),\n",
    "  deliquency as\n",
    "(select loanAccountNumber,\n",
    "case when obs_min_inst_def0 >= 1 and min_inst_def0 = 1 then 1 else 0 end deffpd0,\n",
    "case when obs_min_inst_def10 >=1 and min_inst_def10 =1 then 1 else 0 end deffpd10,\n",
    "case when obs_min_inst_def30 >=1 and min_inst_def30 =1 then 1 else 0 end deffpd30,\n",
    "case when obs_min_inst_def30 >=2 and min_inst_def30 in (1,2) then 1 else 0 end deffspd30,\n",
    "case when obs_min_inst_def30 >=3 and min_inst_def30 in (1,2,3) then 1 else 0 end deffstpd30,\n",
    "case when obs_min_inst_def0 >= 1 then 1 else 0 end flg_mature_fpd0,\n",
    "case when obs_min_inst_def10 >=1 then 1 else 0 end flg_mature_fpd10,\n",
    "case when obs_min_inst_def30 >=1 then 1 else 0 end flg_mature_fpd30,\n",
    "case when obs_min_inst_def30 >=2 then 1 else 0 end flg_mature_fspd_30,\n",
    "case when obs_min_inst_def30 >=3 then 1 else 0 end flg_mature_fstpd_30\n",
    "from prj-prod-dataplatform.risk_credit_mis.loan_deliquency_data),\n",
    "base as\n",
    "(select r.customerId,\n",
    "  r.digitalLoanAccountId,\n",
    "  loanmaster.loanAccountNumber,\n",
    "  r.modelDisplayName,\n",
    "  r.Alpha_cic_sil_score,\n",
    "  coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime)) AS appln_submit_datetime,\n",
    "  date(loanmaster.disbursementDateTime) disbursementdate,\n",
    "  format_date('%Y-%m', coalesce(IF(loanmaster.new_loan_type = 'Flex-up', loanmaster.startApplyDateTime, loanmaster.termsAndConditionsSubmitDateTime),  cast(r.start_time as datetime))) as Application_month, \n",
    "  'Train' Data_selection,  \n",
    "    del.deffstpd30,\n",
    "  del.flg_mature_fstpd_30,\n",
    "  loanmaster.new_loan_type,\n",
    "  modelVersionId,\n",
    "    trenchCategory,\n",
    "    case when loanmaster.loantype='BNPL' and store_type =1 then 'Appliance'\n",
    "    when loanmaster.loantype='BNPL' and store_type =2 then 'Mobile' \n",
    "    when loanmaster.loantype='BNPL' and store_type =3 then 'Mall' \n",
    "    when loanmaster.loantype='BNPL' and store_type not in (1,2,3) then store_tagging\n",
    "    else 'not applicable' end as loan_product_type,\n",
    "    from modelname r\n",
    "  left join risk_credit_mis.loan_master_table loanmaster  ON loanmaster.digitalLoanAccountId = r.digitalLoanAccountId\n",
    "  inner join deliquency del on del.loanAccountNumber = loanmaster.loanAccountNumber\n",
    "  left join(SELECT DISTINCT mer_refferal_code, mer_name mer_name,store_type,store_tagging FROM `dl_loans_db_raw.tdbk_merchant_refferal_mtb`\n",
    "  left join worktable_datachampions.TARGET_SPLIT P on P.STORE_NAME = mer_name\n",
    " qualify row_number() over(partition by mer_refferal_code order by  created_dt desc)=1) sil_category on loanmaster.purpleKey=sil_category.mer_refferal_code\n",
    "  where loanmaster.flagDisbursement = 1\n",
    "  and loanmaster.disbursementDateTime is not null\n",
    "  and r.Alpha_cic_sil_score is not null\n",
    "  and del.flg_mature_fstpd_30 = 1\n",
    "  )\n",
    "  select * from base;\n",
    "  \"\"\"\n",
    "dfd = client.query(sq).to_dataframe()\n",
    "dfd = dfd.drop_duplicates(keep='first')\n",
    "print(f\"The shape of the dataframe downloaded is:\\t {dfd.shape}\")\n",
    "dfd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfd.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79959070",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0aac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(f\"The shape of the concatenated dataframe is:\\t {df_concat.shape}\")\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat.to_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.groupby(['Data_selection','new_loan_type', 'modelVersionId', 'loan_product_type'])['digitalLoanAccountId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff576835",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_results = calculate_periodic_gini_prod_ver_trench_md_col(\n",
    "    df_concat, \n",
    "    'Alpha_cic_sil_score', \n",
    "    'deffstpd30', \n",
    "    'FSTPD30',\n",
    "    model_version_column='modelVersionId',\n",
    "    trench_column='trenchCategory',\n",
    "    loan_type_column='new_loan_type',\n",
    "    loan_product_type_column='loan_product_type',\n",
    "    account_id_column='digitalLoanAccountId'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade49591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the Gini results dataframe is:\\t {gini_results.shape}\")\n",
    "gini_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "f4 = gini_results.copy()\n",
    "f4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd55d6a",
   "metadata": {},
   "source": [
    "## combining the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b60f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "dataframes = [f0, f1, f2, f3, f4]\n",
    "common_columns = ['start_date', 'end_date', 'period', 'Model_Name', 'bad_rate', \n",
    "       'model_version', 'trench_category', 'loan_type', 'loan_product_type']\n",
    "\n",
    "def merge_dataframes(df1, df2):\n",
    "    return pd.merge(df1, df2, on=common_columns, how='outer')\n",
    "\n",
    "final_df = functools.reduce(merge_dataframes, dataframes)\n",
    "\n",
    "final_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['model_version','trench_category']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644bce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = final_df[['start_date', 'end_date', \n",
    "#        'period', 'distinct_accounts', 'Model_Name', 'bad_rate',\n",
    "#        'segment_type', 'model_version', 'trench_category', 'loan_type',\n",
    "#        'loan_product_type', \n",
    "#        'Alpha_cic_sil_score_FPD0_gini',\n",
    "#        'Alpha_cic_sil_score_FPD10_gini',\n",
    "#        'Alpha_cic_sil_score_FPD30_gini',\n",
    "#        'Alpha_cic_sil_score_FSPD30_gini',\n",
    "#        'Alpha_cic_sil_score_FSTPD30_gini']].copy()\n",
    "final_df['Model_display_name'] = 'cic_model_sil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to BigQuery\n",
    "table_id = \"prj-prod-dataplatform.dap_ds_poweruser_playground.cic_sil_score_gini_v2\"\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=\"WRITE_TRUNCATE\",  # or \"WRITE_APPEND\"\n",
    ")\n",
    "job = client.load_table_from_dataframe(final_df, table_id, job_config=job_config)\n",
    "job.result()  # Wait for the job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39941d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['trench_category'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb081d",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f40ac21",
   "metadata": {},
   "source": [
    "Not persude as it is not working in power bi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ba85d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
